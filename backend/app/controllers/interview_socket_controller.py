#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é¢è¯•WebSocketæ§åˆ¶å™¨ - å¤„ç†å®æ—¶æ•°æ®æµ
"""

from flask_socketio import SocketIO, emit, join_room, leave_room
from flask_jwt_extended import decode_token
from flask import request as flask_request
from loguru import logger
from app.services import audio_service, spark_service, vision_service
from app.utils.async_utils import interview_manager
import asyncio
import uuid
import time

# å…¨å±€çš„SocketIOå®ä¾‹
socketio = SocketIO(cors_allowed_origins="*")

# ç”¨äºç¼“å­˜è§†è§‰åˆ†æç»“æœçš„ä¸´æ—¶å­—å…¸
vision_results_cache = {}

def trigger_emotion_feedback(ai_response: str, session_id: str, preferences: dict):
    """
    æ ¹æ®AIåé¦ˆå†…å®¹è§¦å‘é¢è¯•å®˜è¡¨æƒ…åé¦ˆ

    Args:
        ai_response: AIçš„åé¦ˆå†…å®¹
        session_id: ä¼šè¯ID
        preferences: é¢è¯•åå¥½è®¾ç½®
    """
    if not preferences.get('enable_emotion_feedback', True):
        return

    feedback_types = preferences.get('feedback_types', ['nod'])
    if not feedback_types:
        return

    # æ ¹æ®AIåé¦ˆå†…å®¹åˆ¤æ–­åº”è¯¥è§¦å‘ä»€ä¹ˆè¡¨æƒ…
    feedback_type = None

    # ç®€å•çš„å…³é”®è¯åŒ¹é…é€»è¾‘ï¼ˆå®é™…å¯ä»¥ç”¨æ›´å¤æ‚çš„NLPåˆ†æï¼‰
    positive_keywords = ['å¾ˆå¥½', 'ä¸é”™', 'æ­£ç¡®', 'ä¼˜ç§€', 'èµåŒ', 'åŒæ„', 'å¥½çš„']
    questioning_keywords = ['ä½†æ˜¯', 'ç„¶è€Œ', 'ä¸è¿‡', 'ç–‘é—®', 'è´¨ç–‘', 'è€ƒè™‘', 'æ€è€ƒ']
    time_keywords = ['æ—¶é—´', 'å¿«ç‚¹', 'æŠ“ç´§', 'æ•ˆç‡', 'è¿›åº¦']

    if any(keyword in ai_response for keyword in positive_keywords) and 'nod' in feedback_types:
        feedback_type = 'nod'
    elif any(keyword in ai_response for keyword in questioning_keywords) and 'frown' in feedback_types:
        feedback_type = 'frown'
    elif any(keyword in ai_response for keyword in time_keywords) and 'timer' in feedback_types:
        feedback_type = 'timer'

    # å¦‚æœç¡®å®šäº†åé¦ˆç±»å‹ï¼Œå¼‚æ­¥è§¦å‘è¡¨æƒ…åé¦ˆ
    if feedback_type:
        socketio.start_background_task(send_emotion_feedback, session_id, feedback_type, preferences)

def send_emotion_feedback(session_id: str, feedback_type: str, preferences: dict):
    """
    å¼‚æ­¥å‘é€è¡¨æƒ…åé¦ˆ

    Args:
        session_id: ä¼šè¯ID
        feedback_type: åé¦ˆç±»å‹
        preferences: é¢è¯•åå¥½è®¾ç½®
    """
    try:
        session = interview_manager.get_session(session_id)
        if not session:
            return

        avatar_serv = session['services']['avatar']

        # ç”Ÿæˆè¡¨æƒ…åé¦ˆè§†é¢‘
        feedback_result = avatar_serv.create_feedback_expression(feedback_type, preferences)

        if feedback_result.get('success'):
            # å‘é€è¡¨æƒ…åé¦ˆç»™å‰ç«¯
            socketio.emit('emotion_feedback', {
                'feedback_type': feedback_type,
                'video_url': feedback_result.get('video_url'),
                'duration': feedback_result.get('duration', 2.0)
            }, room=session_id)

            logger.info(f"ä¸ºä¼šè¯ {session_id} å‘é€è¡¨æƒ…åé¦ˆ: {feedback_type}")
        else:
            logger.warning(f"è¡¨æƒ…åé¦ˆç”Ÿæˆå¤±è´¥: {feedback_result.get('error')}")

    except Exception as e:
        logger.error(f"å‘é€è¡¨æƒ…åé¦ˆæ—¶å‡ºé”™: {e}")

def on_vision_result_global(session_id: str, vision_data: dict):
    """å…¨å±€å‡½æ•°ï¼Œç”¨äºä»HTTPæ§åˆ¶å™¨æ¥æ”¶è§†è§‰åˆ†æç»“æœ"""
    logger.debug(f"ä¼šè¯ {session_id} æ”¶åˆ°è§†è§‰åˆ†æç»“æœ: {vision_data.get('summary')}")
    # å°†ç»“æœå­˜å…¥ä¸€ä¸ªä¸´æ—¶ç¼“å­˜ï¼Œä»¥ä¾¿ä¸è¯­éŸ³ç»“æœå…³è”
    vision_results_cache[session_id] = vision_data

def register_socket_handlers():
    """æ³¨å†ŒSocket.IOäº‹ä»¶å¤„ç†å™¨"""

    @socketio.on('connect')
    def handle_connect(auth):
        """å¤„ç†å®¢æˆ·ç«¯è¿æ¥"""
        try:
            # ç”Ÿæˆä¸€ä¸ªä¸´æ—¶çš„session IDç”¨äºæ—¥å¿—è®°å½•
            temp_sid = str(uuid.uuid4())[:8]
            logger.info(f"æ”¶åˆ°WebSocketè¿æ¥è¯·æ±‚: auth={auth}, temp_sid={temp_sid}")

            # ä»authä¸­è·å–token
            token = None
            if auth:
                if isinstance(auth, dict):
                    token = auth.get('token')
                elif isinstance(auth, str):
                    token = auth

            if not token:
                logger.warning("WebSocketè¿æ¥ç¼ºå°‘è®¤è¯tokenï¼Œä½¿ç”¨ä¸´æ—¶è®¤è¯")
                # ä¸´æ—¶å…è®¸è¿æ¥ï¼Œä½†è®°å½•è­¦å‘Š
                user_id = 1  # ä¸´æ—¶ä½¿ç”¨ç”¨æˆ·ID 1
                logger.info(f"å®¢æˆ·ç«¯è¿æ¥æˆåŠŸ (ä¸´æ—¶è®¤è¯): user_id={user_id}, temp_sid={temp_sid}")
                emit('connection_response', {'success': True, 'message': 'è¿æ¥æˆåŠŸ (ä¸´æ—¶è®¤è¯)'})
                return True

            # æ‰‹åŠ¨éªŒè¯JWT token
            try:
                decoded_token = decode_token(token)
                user_id = decoded_token['sub']
                logger.info(f"å®¢æˆ·ç«¯è¿æ¥æˆåŠŸ: user_id={user_id}, temp_sid={temp_sid}")
                emit('connection_response', {'success': True, 'message': 'è¿æ¥æˆåŠŸ'})
                return True
            except Exception as e:
                logger.error(f"JWT tokenéªŒè¯å¤±è´¥: {e}")
                # ä¸´æ—¶å…è®¸è¿æ¥ï¼Œä½†è®°å½•é”™è¯¯
                user_id = 1  # ä¸´æ—¶ä½¿ç”¨ç”¨æˆ·ID 1
                logger.info(f"å®¢æˆ·ç«¯è¿æ¥æˆåŠŸ (tokenéªŒè¯å¤±è´¥ï¼Œä½¿ç”¨ä¸´æ—¶è®¤è¯): user_id={user_id}, temp_sid={temp_sid}")
                emit('connection_response', {'success': True, 'message': 'è¿æ¥æˆåŠŸ (ä¸´æ—¶è®¤è¯)'})
                return True

        except Exception as e:
            logger.error(f"WebSocketè¿æ¥å¤„ç†å¼‚å¸¸: {e}")
            return False

    @socketio.on('disconnect')
    def handle_disconnect():
        """å¤„ç†å®¢æˆ·ç«¯æ–­å¼€è¿æ¥"""
        temp_sid = str(uuid.uuid4())[:8]
        logger.info(f"å®¢æˆ·ç«¯æ–­å¼€è¿æ¥: temp_sid={temp_sid}")
        # æ³¨æ„ï¼šç”±äºæ— æ³•è·å–çœŸå®çš„session IDï¼Œæš‚æ—¶è·³è¿‡æ¸…ç†
        # è¿™æ˜¯ä¸€ä¸ªä¸´æ—¶è§£å†³æ–¹æ¡ˆï¼Œå®é™…åº”ç”¨ä¸­éœ€è¦æ›´å¥½çš„sessionç®¡ç†
        logger.info("WebSocketæ–­å¼€è¿æ¥å¤„ç†å®Œæˆ")

    @socketio.on('join_interview')
    def handle_join_interview(data):
        """ç”¨æˆ·åŠ å…¥é¢è¯•æˆ¿é—´"""
        session_id = data.get('session_id')
        
        if not session_id:
            logger.error("åŠ å…¥é¢è¯•å¤±è´¥: æœªæä¾›session_id")
            emit('error', {'message': 'éœ€è¦æä¾›session_id'})
            return

        # å°†ç”¨æˆ·åŠ å…¥ç‰¹å®šæˆ¿é—´ï¼Œä»¥ä¾¿å®šå‘å‘é€æ¶ˆæ¯
        join_room(session_id)
        # å¼‚æ­¥æ³¨å†Œ - ä½¿ç”¨ä¸´æ—¶session ID
        temp_sid = str(uuid.uuid4())[:8]
        asyncio.run(interview_manager.register_sid(session_id, temp_sid))
        logger.info(f"ç”¨æˆ· (temp_sid={temp_sid}) å·²åŠ å…¥é¢è¯•æˆ¿é—´: {session_id}")
        
        # é€šçŸ¥å‰ç«¯åŠ å…¥æˆåŠŸ
        emit('joined', {'success': True, 'session_id': session_id})
    
    @socketio.on('start_streaming')
    def handle_start_streaming(data):
        # é¦–å…ˆå°è¯•ä»dataä¸­è·å–token
        token = data.get('token')
        user_id = None

        # å¦‚æœdataä¸­æ²¡æœ‰tokenï¼Œä½¿ç”¨ä¸´æ—¶è®¤è¯ï¼ˆä¸è¿æ¥æ—¶ä¿æŒä¸€è‡´ï¼‰
        if not token:
            user_id = 1  # ä¸´æ—¶ä½¿ç”¨ï¼Œå› ä¸ºè¿æ¥æ—¶å·²ç»éªŒè¯è¿‡
            logger.info(f"ä½¿ç”¨è¿æ¥æ—¶çš„è®¤è¯ä¿¡æ¯ï¼Œç”¨æˆ·ID: {user_id}")
        else:
            try:
                decoded = decode_token(token)
                user_id = decoded['sub']
                logger.info(f"TokenéªŒè¯æˆåŠŸï¼Œç”¨æˆ·ID: {user_id}")
            except Exception as e:
                logger.error(f"TokenéªŒè¯å¤±è´¥: {e}")
                emit('error', {'message': 'TokenéªŒè¯å¤±è´¥ï¼Œè¯·é‡æ–°ç™»å½•'})
                return

        try:
            session_id = data.get('session_id')
            session = interview_manager.get_session(session_id)

            if not session:
                logger.error(f"å¯åŠ¨æµå¼ä¼ è¾“å¤±è´¥: æœªæ‰¾åˆ°ä¼šè¯ (session_id={session_id})")
                emit('error', {'message': 'ä¼šè¯ä¸å­˜åœ¨'})
                return

            # éªŒè¯ä¼šè¯æ˜¯å¦å±äºå½“å‰ç”¨æˆ·
            session_user_id = session.get('user_id')
            logger.info(f"æƒé™éªŒè¯: è¯·æ±‚ç”¨æˆ·ID={user_id}, ä¼šè¯ç”¨æˆ·ID={session_user_id}, ä¼šè¯è¯¦æƒ…={session}")
            if session_user_id != int(user_id):
                logger.error(f"ç”¨æˆ· {user_id} æ— æƒè®¿é—®ä¼šè¯ {session_id} (ä¼šè¯å±äºç”¨æˆ· {session_user_id})")
                emit('error', {'message': 'æ— æƒè®¿é—®æ­¤ä¼šè¯'})
                return

            # è·å–é¢è¯•é…ç½®å’Œåå¥½è®¾ç½®
            interview_config = session.get('context', {}).get('interview_config', {})
            interview_preferences = session.get('context', {}).get('interview_preferences', {})

            logger.info(f"ä¸ºä¼šè¯ {session_id} å¯åŠ¨æµå¼å¤„ç†ç®¡é“...")
            logger.info(f"é¢è¯•é…ç½®: {interview_config}")
            logger.info(f"é¢è¯•åå¥½: {interview_preferences}")

            # ä½¿ç”¨åŒæ­¥ç‰ˆæœ¬çš„æµå¼ç®¡é“è®¾ç½®
            setup_streaming_pipeline_sync(session_id, interview_config, interview_preferences)

            # å¯åŠ¨å®æ—¶åé¦ˆå®šæ—¶å™¨
            def run_feedback_timer():
                import asyncio
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                try:
                    loop.run_until_complete(start_realtime_feedback_timer(session_id))
                finally:
                    loop.close()

            socketio.start_background_task(run_feedback_timer)

            emit('streaming_started', {'success': True})

        except Exception as e:
            logger.error(f"å¯åŠ¨æµå¼ä¼ è¾“å¼‚å¸¸: {e}")
            emit('error', {'message': 'å¯åŠ¨æµå¼ä¼ è¾“å¤±è´¥'})

    @socketio.on('audio_stream')
    def handle_audio_stream(data):
        """å¤„ç†å‰ç«¯å‘é€çš„éŸ³é¢‘æµ"""
        # æš‚æ—¶ç®€åŒ–å¤„ç†ï¼Œä¸ä¾èµ–session ID
        temp_sid = str(uuid.uuid4())[:8]
        logger.debug(f"æ”¶åˆ°éŸ³é¢‘æµæ•°æ®: temp_sid={temp_sid}, æ•°æ®é•¿åº¦={len(data) if data else 0}")
        # æš‚æ—¶è·³è¿‡å…·ä½“å¤„ç†
        return
    
    @socketio.on('request_next_question')
    def handle_next_question_request(data):
        token = data.get('token')
        if not token:
            emit('error', {'message': 'ç¼ºå°‘è®¤è¯token'})
            return
        try:
            decoded = decode_token(token)
            user_id = decoded['sub']
            session_id = data.get('session_id')
            logger.info(f"æ”¶åˆ°ä¼šè¯ {session_id} çš„æ‰‹åŠ¨ä¸‹ä¸€é—®é¢˜è¯·æ±‚ï¼Œç”¨æˆ·ID: {user_id}")
            socketio.start_background_task(generate_and_serve_next_question, session_id)
        except Exception as e:
            logger.error(f"Token validation failed: {str(e)}")
            emit('error', {'message': 'Invalid or expired token'})
            return
    
    @socketio.on('leave_interview')
    def handle_leave_interview(data):
        """ç”¨æˆ·ç¦»å¼€é¢è¯•æˆ¿é—´"""
        session_id = data.get('session_id')
        if session_id:
            leave_room(session_id)
            temp_sid = str(uuid.uuid4())[:8]
            logger.info(f"ç”¨æˆ· (temp_sid={temp_sid}) å·²ç¦»å¼€é¢è¯•æˆ¿é—´: {session_id}")
            # å¯åœ¨æ­¤å¤„å¤„ç†é¢è¯•ä¸­æ–­é€»è¾‘

    @socketio.on('end_interview')
    def handle_end_interview(data):
        """ç»“æŸé¢è¯•"""
        try:
            session_id = data.get('session_id')
            if not session_id:
                emit('error', {'message': 'ç¼ºå°‘session_id'})
                return

            logger.info(f"æ”¶åˆ°ç»“æŸé¢è¯•è¯·æ±‚: {session_id}")

            # è·å–ä¼šè¯
            session = interview_manager.get_session(session_id)
            if not session:
                emit('error', {'message': 'ä¼šè¯ä¸å­˜åœ¨'})
                return

            # ç»“æŸä¼šè¯
            interview_manager.end_session(session_id)

            # é€šçŸ¥å‰ç«¯é¢è¯•å·²ç»“æŸ
            emit('interview_ended', {
                'success': True,
                'message': 'é¢è¯•å·²ç»“æŸ',
                'session_id': session_id
            })

            logger.info(f"é¢è¯•å·²ç»“æŸ: {session_id}")

        except Exception as e:
            logger.error(f"ç»“æŸé¢è¯•å¤±è´¥: {e}")
            emit('error', {'message': f'ç»“æŸé¢è¯•å¤±è´¥: {str(e)}'})

def setup_streaming_pipeline_sync(session_id: str, interview_config: dict = None, interview_preferences: dict = None):
    """ä¸ºæŒ‡å®šä¼šè¯è®¾ç½®å®Œæ•´çš„å®æ—¶åé¦ˆæµå¼å¤„ç†ç®¡é“ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰"""
    try:
        session = interview_manager.get_session(session_id)
        if not session:
            logger.error(f"æ— æ³•è®¾ç½®ç®¡é“ï¼šæœªæ‰¾åˆ°ä¼šè¯ {session_id}")
            return

        # å¦‚æœæ²¡æœ‰ä¼ é€’é…ç½®ï¼Œä»ä¼šè¯ä¸Šä¸‹æ–‡ä¸­è·å–
        if not interview_config:
            interview_config = session.get('context', {}).get('interview_config', {})
        if not interview_preferences:
            interview_preferences = session.get('context', {}).get('interview_preferences', {})

        logger.info(f"å¼€å§‹ä¸ºä¼šè¯ {session_id} è®¾ç½®å®Œæ•´çš„å®æ—¶åé¦ˆç®¡é“")

        # è·å–Flaskåº”ç”¨å®ä¾‹
        from flask import current_app
        app = current_app._get_current_object()

        # åˆå§‹åŒ–æ‰€æœ‰æœåŠ¡
        from app.services.audio_service import AudioService
        from app.services.vision_service import VisionService

        # åˆ›å»ºæœåŠ¡å®ä¾‹ï¼Œä¼ å…¥Flaskåº”ç”¨å®ä¾‹
        audio_service = AudioService(app=app)
        vision_service = VisionService()
        spark_service = session['services']['spark']

        # å­˜å‚¨æœåŠ¡å®ä¾‹åˆ°ä¼šè¯ä¸­
        session['services']['audio'] = audio_service
        session['services']['vision'] = vision_service

        # åˆå§‹åŒ–å®æ—¶æ•°æ®å­˜å‚¨
        session['realtime_data'] = {
            'transcriptions': [],  # è¯­éŸ³è½¬å†™å†å²
            'vision_results': [],  # è§†è§‰åˆ†æå†å²
            'audio_analysis': [],  # è¯­éŸ³åˆ†æå†å²
            'last_feedback_time': time.time()
        }

        logger.info(f"ä¼šè¯ {session_id} çš„å®æ—¶åé¦ˆç®¡é“è®¾ç½®å®Œæˆ")

        # è·å–Flaskåº”ç”¨å®ä¾‹
        from flask import current_app
        app = current_app._get_current_object()

        # å¯åŠ¨å®æ—¶è¯­éŸ³è½¬å†™ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰
        socketio.start_background_task(start_realtime_transcription_sync, session_id, audio_service, app)

        # å¯åŠ¨å®æ—¶æˆªå›¾å’Œè§†è§‰åˆ†æï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰
        socketio.start_background_task(start_realtime_vision_analysis_sync, session_id, vision_service, app)

        logger.info(f"ä¼šè¯ {session_id} æ‰€æœ‰å®æ—¶æœåŠ¡å·²å¯åŠ¨")

    except Exception as e:
        logger.error(f"è®¾ç½®æµå¼ç®¡é“æ—¶å‡ºé”™ (session_id={session_id}): {e}")
        import traceback
        logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")

def start_realtime_transcription_sync(session_id: str, audio_service, app):
    """å¯åŠ¨å®æ—¶è¯­éŸ³è½¬å†™ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰"""
    try:
        logger.info(f"å¼€å§‹ä¸ºä¼šè¯ {session_id} å¯åŠ¨å®æ—¶è¯­éŸ³è½¬å†™")

        import time
        import asyncio

        # è®¾ç½®è½¬å†™å›è°ƒå‡½æ•°
        def transcription_callback(result):
            """å¤„ç†è½¬å†™ç»“æœçš„å›è°ƒå‡½æ•°"""
            try:
                session = interview_manager.get_session(session_id)
                if session:
                    # å¤„ç†è½¬å†™ç»“æœï¼ˆå¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–å­—å…¸ï¼‰
                    if isinstance(result, dict):
                        text = result.get('text', '')
                        confidence = result.get('confidence', 0.8)
                        is_final = result.get('is_final', False)
                    else:
                        text = str(result)
                        confidence = 0.8
                        is_final = False
                    
                    if text:
                        # å­˜å‚¨è½¬å†™ç»“æœåˆ°ä¼šè¯
                        if 'realtime_data' not in session:
                            session['realtime_data'] = {'transcriptions': [], 'vision_analysis': [], 'audio_analysis': []}

                        session['realtime_data']['transcriptions'].append({
                            'text': text,
                            'timestamp': time.time(),
                            'confidence': confidence,
                            'is_final': is_final
                        })

                        # ä¿æŒæœ€è¿‘50æ¡è®°å½•
                        if len(session['realtime_data']['transcriptions']) > 50:
                            session['realtime_data']['transcriptions'] = session['realtime_data']['transcriptions'][-50:]

                        logger.info(f"æ”¶é›†åˆ°çœŸå®è¯­éŸ³è½¬å†™: {text}")
                        
                        # ç«‹å³è§¦å‘AIåé¦ˆ
                        generate_realtime_feedback_sync(session_id)
            except Exception as e:
                logger.error(f"å¤„ç†è½¬å†™å›è°ƒå¤±è´¥: {e}")

        # å¯åŠ¨è®¯é£å®æ—¶è¯­éŸ³è½¬å†™
        try:
            # åœ¨Flaskåº”ç”¨ä¸Šä¸‹æ–‡ä¸­å¯åŠ¨è½¬å†™
            with app.app_context():
                audio_service.start_realtime_transcription(session_id, transcription_callback)
                logger.info(f"è®¯é£å®æ—¶è¯­éŸ³è½¬å†™å¯åŠ¨æˆåŠŸ: {session_id}")

                # å°†audio_serviceæ³¨å…¥åˆ°sessionä¸­
                current_session = interview_manager.get_session(session_id)
                if current_session:
                    current_session['services']['audio'] = audio_service
        except Exception as e:
            logger.error(f"å¯åŠ¨è®¯é£è¯­éŸ³è½¬å†™å¤±è´¥: {e}")
            logger.error(f"è®¯é£å®æ—¶è¯­éŸ³è½¬å†™å¯åŠ¨å¤±è´¥: {session_id}")

    except Exception as e:
        logger.error(f"å¯åŠ¨å®æ—¶è¯­éŸ³è½¬å†™å¤±è´¥: {e}")
        # ä¸å†ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼Œåªä½¿ç”¨çœŸå®çš„è®¯é£API

# æ¨¡æ‹Ÿè¯­éŸ³è½¬å†™å‡½æ•°å·²åˆ é™¤ï¼Œåªä½¿ç”¨çœŸå®çš„è®¯é£API

def start_realtime_vision_analysis_sync(session_id: str, vision_service, app):
    """å¯åŠ¨å®æ—¶è§†è§‰åˆ†æï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰"""
    try:
        logger.info(f"å¼€å§‹ä¸ºä¼šè¯ {session_id} å¯åŠ¨å®æ—¶è§†è§‰åˆ†æ")

        import time

        while True:
            try:
                # è·å–ä¼šè¯
                session = interview_manager.get_session(session_id)
                if not session:
                    logger.info(f"ä¼šè¯ {session_id} å·²ç»“æŸï¼Œåœæ­¢è§†è§‰åˆ†æ")
                    break

                # æˆªå–å±å¹•æˆªå›¾
                screenshot_data = vision_service.capture_screenshot()

                if screenshot_data:
                    # åœ¨Flaskåº”ç”¨ä¸Šä¸‹æ–‡ä¸­ä½¿ç”¨è®¯é£è¡¨æƒ…åˆ†æAPI
                    with app.app_context():
                        analysis_result = vision_service.analyze_expression_xunfei(screenshot_data)

                    # å­˜å‚¨åˆ†æç»“æœåˆ°ä¼šè¯
                    if 'realtime_data' not in session:
                        session['realtime_data'] = {'transcriptions': [], 'vision_analysis': [], 'audio_analysis': []}

                    # ç¡®ä¿vision_analysisé”®å­˜åœ¨
                    if 'vision_analysis' not in session['realtime_data']:
                        session['realtime_data']['vision_analysis'] = []

                    if analysis_result:
                        session['realtime_data']['vision_analysis'].append({
                            'analysis': analysis_result,
                            'timestamp': time.time(),
                            'screenshot_size': len(screenshot_data)
                        })

                        # ä¿æŒæœ€è¿‘20æ¡è®°å½•
                        if len(session['realtime_data']['vision_analysis']) > 20:
                            session['realtime_data']['vision_analysis'] = session['realtime_data']['vision_analysis'][-20:]

                        emotion = analysis_result.get('emotion', 'unknown')
                        confidence = analysis_result.get('confidence', 0.0)
                        logger.info(f"å®Œæˆè®¯é£è¡¨æƒ…åˆ†æï¼Œæˆªå›¾å¤§å°: {len(screenshot_data)} bytes, æƒ…ç»ª: {emotion}, ç½®ä¿¡åº¦: {confidence:.3f}")
                    else:
                        logger.warning("è®¯é£è¡¨æƒ…åˆ†æè¿”å›ç©ºç»“æœ")

                # æ¯10ç§’åˆ†æä¸€æ¬¡
                time.sleep(10)

            except Exception as e:
                logger.error(f"è§†è§‰åˆ†æå¾ªç¯å¼‚å¸¸: {e}")
                time.sleep(10)

    except Exception as e:
        logger.error(f"å¯åŠ¨å®æ—¶è§†è§‰åˆ†æå¤±è´¥: {e}")

async def start_realtime_transcription_task(session_id: str, audio_service):
    """å¯åŠ¨å®æ—¶è¯­éŸ³è½¬å†™ä»»åŠ¡"""
    try:
        # è®¾ç½®è½¬å†™ç»“æœå›è°ƒ
        def on_transcription_result(text: str, is_final: bool = False):
            session = interview_manager.get_session(session_id)
            if session and text.strip():
                # å­˜å‚¨è½¬å†™ç»“æœ
                transcription_data = {
                    'text': text,
                    'timestamp': time.time(),
                    'is_final': is_final
                }
                session['realtime_data']['transcriptions'].append(transcription_data)

                # ä¿æŒæœ€è¿‘30ç§’çš„è½¬å†™è®°å½•
                current_time = time.time()
                session['realtime_data']['transcriptions'] = [
                    t for t in session['realtime_data']['transcriptions']
                    if current_time - t['timestamp'] <= 30
                ]

                logger.debug(f"ä¼šè¯ {session_id} æ”¶åˆ°è½¬å†™: {text[:50]}...")

        # å¯åŠ¨è¯­éŸ³è½¬å†™WebSocketè¿æ¥
        await audio_service.start_transcription_websocket(session_id, on_transcription_result)

    except Exception as e:
        logger.error(f"å¯åŠ¨å®æ—¶è¯­éŸ³è½¬å†™ä»»åŠ¡å¤±è´¥: {e}")

async def start_realtime_vision_analysis_task(session_id: str, vision_service):
    """å¯åŠ¨å®æ—¶è§†è§‰åˆ†æä»»åŠ¡ï¼ˆæ¯10ç§’æˆªå›¾åˆ†æï¼‰"""
    try:
        async def vision_analysis_loop():
            while True:
                try:
                    session = interview_manager.get_session(session_id)
                    if not session:
                        break

                    # æ¨¡æ‹Ÿæˆªå›¾ï¼ˆå®é™…åº”è¯¥ä»å‰ç«¯è·å–ï¼‰
                    # è¿™é‡Œéœ€è¦å‰ç«¯å®šæœŸå‘é€æˆªå›¾æ•°æ®
                    logger.debug(f"ä¼šè¯ {session_id} ç­‰å¾…è§†è§‰åˆ†ææ•°æ®...")

                    # ç­‰å¾…10ç§’åè¿›è¡Œä¸‹ä¸€æ¬¡åˆ†æ
                    await asyncio.sleep(10)

                except Exception as e:
                    logger.error(f"è§†è§‰åˆ†æå¾ªç¯é”™è¯¯: {e}")
                    await asyncio.sleep(10)

        # åœ¨åå°å¯åŠ¨è§†è§‰åˆ†æå¾ªç¯
        await vision_analysis_loop()

    except Exception as e:
        logger.error(f"å¯åŠ¨å®æ—¶è§†è§‰åˆ†æä»»åŠ¡å¤±è´¥: {e}")

async def start_realtime_transcription(session_id: str, audio_service):
    """å¯åŠ¨å®æ—¶è¯­éŸ³è½¬å†™"""
    try:
        # è®¾ç½®è½¬å†™ç»“æœå›è°ƒ
        def on_transcription_result(text: str, is_final: bool = False):
            session = interview_manager.get_session(session_id)
            if session and text.strip():
                # å­˜å‚¨è½¬å†™ç»“æœ
                transcription_data = {
                    'text': text,
                    'timestamp': time.time(),
                    'is_final': is_final
                }
                session['realtime_data']['transcriptions'].append(transcription_data)

                # ä¿æŒæœ€è¿‘30ç§’çš„è½¬å†™è®°å½•
                current_time = time.time()
                session['realtime_data']['transcriptions'] = [
                    t for t in session['realtime_data']['transcriptions']
                    if current_time - t['timestamp'] <= 30
                ]

                logger.debug(f"ä¼šè¯ {session_id} æ”¶åˆ°è½¬å†™: {text[:50]}...")

        # å¯åŠ¨è¯­éŸ³è½¬å†™WebSocketè¿æ¥
        await audio_service.start_transcription_websocket(session_id, on_transcription_result)

    except Exception as e:
        logger.error(f"å¯åŠ¨å®æ—¶è¯­éŸ³è½¬å†™å¤±è´¥: {e}")

async def start_realtime_vision_analysis(session_id: str, vision_service):
    """å¯åŠ¨å®æ—¶è§†è§‰åˆ†æï¼ˆæ¯10ç§’æˆªå›¾åˆ†æï¼‰"""
    try:
        async def vision_analysis_loop():
            while True:
                try:
                    session = interview_manager.get_session(session_id)
                    if not session:
                        break

                    # æ¨¡æ‹Ÿæˆªå›¾ï¼ˆå®é™…åº”è¯¥ä»å‰ç«¯è·å–ï¼‰
                    # è¿™é‡Œéœ€è¦å‰ç«¯å®šæœŸå‘é€æˆªå›¾æ•°æ®
                    logger.debug(f"ä¼šè¯ {session_id} ç­‰å¾…è§†è§‰åˆ†ææ•°æ®...")

                    # ç­‰å¾…10ç§’åè¿›è¡Œä¸‹ä¸€æ¬¡åˆ†æ
                    await asyncio.sleep(10)

                except Exception as e:
                    logger.error(f"è§†è§‰åˆ†æå¾ªç¯é”™è¯¯: {e}")
                    await asyncio.sleep(10)

        # åœ¨åå°å¯åŠ¨è§†è§‰åˆ†æå¾ªç¯
        asyncio.create_task(vision_analysis_loop())

    except Exception as e:
        logger.error(f"å¯åŠ¨å®æ—¶è§†è§‰åˆ†æå¤±è´¥: {e}")

async def generate_realtime_feedback(session_id: str, audio_chunk=None):
    """ç”ŸæˆåŸºäºå¤šæ¨¡æ€åˆ†æçš„å®æ—¶åé¦ˆ"""
    try:
        from app.utils.async_utils import interview_manager
        session = interview_manager.get_session(session_id)
        if not session:
            return

        # è·å–å®æ—¶æ•°æ®
        realtime_data = session.get('realtime_data', {})
        current_question = session.get('context', {}).get('current_question_data', {})
        interview_config = session.get('context', {}).get('interview_config', {})

        # ä½¿ç”¨audio_chunkå‚æ•°ï¼ˆé¿å…æœªä½¿ç”¨è­¦å‘Šï¼‰
        if audio_chunk:
            logger.debug(f"å¤„ç†éŸ³é¢‘å—æ•°æ®: {len(audio_chunk) if audio_chunk else 0} bytes")

        # è·å–æœ€è¿‘çš„è½¬å†™æ–‡æœ¬ï¼ˆæœ€è¿‘30ç§’ï¼‰
        recent_transcriptions = realtime_data.get('transcriptions', [])
        current_time = time.time()
        recent_text = " ".join([
            t['text'] for t in recent_transcriptions
            if current_time - t['timestamp'] <= 30
        ])

        # å¦‚æœæ²¡æœ‰å®æ—¶è½¬å†™æ–‡æœ¬ï¼Œå°è¯•è·å–ç”¨æˆ·å¯èƒ½çš„è¾“å…¥å†…å®¹
        if not recent_text:
            # æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–å½¢å¼çš„ç”¨æˆ·è¾“å…¥
            user_inputs = realtime_data.get('user_inputs', [])
            if user_inputs:
                recent_text = " ".join([
                    inp['content'] for inp in user_inputs[-3:]  # æœ€è¿‘3æ¡è¾“å…¥
                    if current_time - inp.get('timestamp', 0) <= 60
                ])

        # æ£€æŸ¥æ˜¯å¦æœ‰æ¨¡æ‹Ÿè½¬å†™æ•°æ®
        if not recent_text:
            mock_transcriptions = [
                t for t in recent_transcriptions
                if t.get('source') == 'mock_mode' and current_time - t['timestamp'] <= 60
            ]
            if mock_transcriptions:
                recent_text = " ".join([t['text'] for t in mock_transcriptions[-2:]])  # æœ€è¿‘2æ¡æ¨¡æ‹Ÿæ•°æ®

        # è·å–æœ€è¿‘çš„è§†è§‰åˆ†æç»“æœ - ä¿®å¤æ•°æ®è·å–è·¯å¾„
        recent_vision = realtime_data.get('vision_analysis', [])  # ä¿®æ­£å­—æ®µå
        latest_vision = recent_vision[-1] if recent_vision else None

        # è·å–æœ€è¿‘çš„è¯­éŸ³åˆ†æç»“æœ
        recent_audio_analysis = realtime_data.get('audio_analysis', [])
        latest_audio_analysis = recent_audio_analysis[-1] if recent_audio_analysis else None

        # æ£€æŸ¥æ˜¯å¦å·²æœ‰åé¦ˆå†å²ï¼Œå¦‚æœæœ‰åˆ™ä¸å‘é€"æ­£åœ¨åˆ†æä¸­"çŠ¶æ€
        session_data = interview_manager.get_session(session_id)
        has_previous_feedback = False
        if session_data and 'realtime_data' in session_data:
            realtime_data_history = session_data['realtime_data']
            has_previous_feedback = bool(realtime_data_history.get('ai_feedback_history', []))

        # åªåœ¨æ²¡æœ‰å†å²åé¦ˆæ—¶å‘é€"æ­£åœ¨åˆ†æä¸­"çŠ¶æ€
        if not has_previous_feedback:
            socketio.emit('realtime_feedback', {
                'success': True,
                'feedback': {
                    'audio': "æ­£åœ¨åˆ†æè¯­éŸ³æ•°æ®...",
                    'behavior': "æ­£åœ¨åˆ†æè¡Œä¸ºè¡¨ç°...",
                    'technical': "æ­£åœ¨åˆ†æå›ç­”å†…å®¹...",
                    'stress': "æ­£åœ¨è¯„ä¼°é¢è¯•çŠ¶æ€..."
                },
                'timestamp': current_time,
                'ai_generated': False,
                'analyzing': True,
                'data_sources': {
                    'has_transcription': bool(recent_text),
                    'has_vision': bool(latest_vision),
                    'has_audio_analysis': bool(latest_audio_analysis)
                }
            }, room=session_id)

        # æ„å»ºç»¼åˆåˆ†ææç¤º
        feedback_prompt = f"""
ä½œä¸ºä¸“ä¸šçš„é¢è¯•å®˜ï¼Œè¯·åŸºäºä»¥ä¸‹å¤šæ¨¡æ€æ•°æ®ç»™å‡ºå®æ—¶åé¦ˆå»ºè®®ï¼š

ã€é¢è¯•ä¿¡æ¯ã€‘
å½“å‰é—®é¢˜ï¼š{current_question.get('content', 'æš‚æ— é—®é¢˜')}
é¢è¯•ç±»å‹ï¼š{interview_config.get('interview_mode', 'technical')}
èŒä½ï¼š{interview_config.get('position', 'AIç®—æ³•å·¥ç¨‹å¸ˆ')}

ã€è¯­éŸ³è½¬å†™å†…å®¹ï¼ˆæœ€è¿‘30ç§’ï¼‰ã€‘
{recent_text if recent_text else 'æš‚æ— è¯­éŸ³å†…å®¹'}

ã€è§†è§‰åˆ†æç»“æœã€‘
{f"æ£€æµ‹åˆ°æƒ…ç»ª: {latest_vision['analysis'].get('emotion', 'unknown')}, ç½®ä¿¡åº¦: {latest_vision['analysis'].get('confidence', 0.0):.2f}" if latest_vision and latest_vision.get('analysis') else 'æš‚æ— è§†è§‰åˆ†æ'}

ã€è¯­éŸ³åˆ†æç»“æœã€‘
{latest_audio_analysis.get('summary', 'æš‚æ— è¯­éŸ³åˆ†æ') if latest_audio_analysis else 'æš‚æ— è¯­éŸ³åˆ†æ'}

è¯·ä»ä»¥ä¸‹4ä¸ªç»´åº¦ç»™å‡ºç®€çŸ­çš„å®æ—¶åé¦ˆï¼ˆæ¯ä¸ªç»´åº¦1-2å¥è¯ï¼‰ï¼š
1. è¯­éŸ³è¡¨è¾¾ï¼šåŸºäºè¯­éŸ³åˆ†æçš„è¯­é€Ÿã€è¯­è°ƒã€å‘éŸ³ç­‰åé¦ˆ
2. è¡Œä¸ºè¡¨ç°ï¼šåŸºäºè§†è§‰åˆ†æçš„è‚¢ä½“è¯­è¨€ã€çœ¼ç¥äº¤æµã€è¡¨æƒ…ç­‰åé¦ˆ
3. æŠ€æœ¯å†…å®¹ï¼šåŸºäºè½¬å†™å†…å®¹çš„æŠ€æœ¯æ·±åº¦ã€å‡†ç¡®æ€§ã€é€»è¾‘æ€§åé¦ˆ
4. å‹åŠ›åº”å¯¹ï¼šç»¼åˆåˆ†ææƒ…ç»ªç¨³å®šæ€§ã€æ€ç»´æ¸…æ™°åº¦ã€é€‚åº”èƒ½åŠ›

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼š
{{
    "audio": "è¯­éŸ³è¡¨è¾¾åé¦ˆ",
    "behavior": "è¡Œä¸ºè¡¨ç°åé¦ˆ",
    "technical": "æŠ€æœ¯å†…å®¹åé¦ˆ",
    "stress": "å‹åŠ›åº”å¯¹åé¦ˆ"
}}
"""

        # è°ƒç”¨AIæ¨¡å‹ç”Ÿæˆåé¦ˆ
        try:
            spark_service = session.get('services', {}).get('spark')
            if spark_service:
                # ç›´æ¥è°ƒç”¨AIæœåŠ¡ï¼Œä¸éœ€è¦åº”ç”¨ä¸Šä¸‹æ–‡
                ai_result = spark_service.chat_completion_http(
                    [{"role": "user", "content": feedback_prompt}],
                    "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é¢è¯•å®˜ï¼Œè¯·åŸºäºå¤šæ¨¡æ€æ•°æ®ç»™å‡ºå»ºè®¾æ€§çš„å®æ—¶åé¦ˆã€‚"
                )

                if ai_result and ai_result.get('success'):
                    ai_feedback_text = ai_result.get('message', '')
                    logger.info(f"AIåŸå§‹è¿”å›å†…å®¹: {ai_feedback_text}")

                    # å°è¯•è§£æJSONæ ¼å¼çš„åé¦ˆ
                    import json
                    try:
                        # å°è¯•æå–JSONéƒ¨åˆ†ï¼ˆå¯èƒ½AIè¿”å›çš„å†…å®¹åŒ…å«å…¶ä»–æ–‡æœ¬ï¼‰
                        import re
                        json_match = re.search(r'\{.*\}', ai_feedback_text, re.DOTALL)
                        if json_match:
                            json_str = json_match.group()
                            feedback = json.loads(json_str)
                            logger.info(f"AIç”Ÿæˆçš„å®æ—¶åé¦ˆè§£ææˆåŠŸ: {feedback}")
                        else:
                            raise ValueError("æœªæ‰¾åˆ°JSONæ ¼å¼å†…å®¹")
                    except Exception as parse_error:
                        logger.error(f"AIåé¦ˆJSONè§£æå¤±è´¥: {parse_error}, åŸå§‹å†…å®¹: {ai_feedback_text}")
                        # å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ ¼å¼
                        feedback = {
                            'audio': "è¯­é€Ÿé€‚ä¸­ï¼Œè¡¨è¾¾æ¸…æ™°",
                            'behavior': "è¡¨ç°è‡ªç„¶ï¼Œäº’åŠ¨è‰¯å¥½",
                            'technical': ai_feedback_text[:100] + "..." if len(ai_feedback_text) > 100 else ai_feedback_text,
                            'stress': "æƒ…ç»ªç¨³å®šï¼Œåº”å¯¹ä»å®¹"
                        }
                else:
                    # AIè°ƒç”¨å¤±è´¥æ—¶çš„å¤‡ç”¨åé¦ˆ
                    feedback = {
                        'audio': "è¯­é€Ÿé€‚ä¸­ï¼Œå»ºè®®ä¿æŒå½“å‰èŠ‚å¥",
                        'behavior': "è¡¨ç°è‡ªç„¶ï¼Œç»§ç»­ä¿æŒ",
                        'technical': "å›ç­”æ€è·¯æ¸…æ™°ï¼Œå¯ä»¥æ›´è¯¦ç»†ä¸€äº›",
                        'stress': "æƒ…ç»ªç¨³å®šï¼Œè¡¨ç°è‰¯å¥½"
                    }
            else:
                # æ²¡æœ‰æ•°æ®æ—¶çš„å¤‡ç”¨åé¦ˆ
                feedback = {
                    'audio': "ç­‰å¾…è¯­éŸ³æ•°æ®åˆ†æ...",
                    'behavior': "ç­‰å¾…è§†è§‰æ•°æ®åˆ†æ...",
                    'technical': "ç­‰å¾…å›ç­”å†…å®¹åˆ†æ...",
                    'stress': "é¢è¯•çŠ¶æ€è‰¯å¥½ï¼Œç»§ç»­ä¿æŒ"
                }

        except Exception as ai_error:
            logger.error(f"AIåé¦ˆç”Ÿæˆå¤±è´¥: {ai_error}")
            # AIè°ƒç”¨å¼‚å¸¸æ—¶çš„å¤‡ç”¨åé¦ˆ
            feedback = {
                'audio': "è¯­é€Ÿé€‚ä¸­ï¼Œè¡¨è¾¾æ¸…æ™°",
                'behavior': "è¡¨ç°è‡ªç„¶ï¼Œäº’åŠ¨è‰¯å¥½",
                'technical': "å›ç­”é€»è¾‘æ¸…æ™°ï¼Œç»§ç»­ä¿æŒ",
                'stress': "æƒ…ç»ªç¨³å®šï¼Œåº”å¯¹è‰¯å¥½"
            }

        # ä¿å­˜åé¦ˆå†å²
        if session_data:
            if 'realtime_data' not in session_data:
                session_data['realtime_data'] = {}
            if 'ai_feedback_history' not in session_data['realtime_data']:
                session_data['realtime_data']['ai_feedback_history'] = []

            session_data['realtime_data']['ai_feedback_history'].append({
                'feedback': feedback,
                'timestamp': current_time,
                'data_sources': {
                    'has_transcription': bool(recent_text),
                    'has_vision': bool(latest_vision),
                    'has_audio_analysis': bool(latest_audio_analysis)
                }
            })

        # å‘é€å®æ—¶åé¦ˆåˆ°å‰ç«¯
        socketio.emit('realtime_feedback', {
            'success': True,
            'feedback': feedback,
            'timestamp': current_time,
            'ai_generated': True,
            'analyzing': False,  # åˆ†æå®Œæˆ
            'data_sources': {
                'has_transcription': bool(recent_text),
                'has_vision': bool(latest_vision),
                'has_audio_analysis': bool(latest_audio_analysis)
            }
        }, room=session_id)

        # æ›´æ–°æœ€ååé¦ˆæ—¶é—´
        realtime_data['last_feedback_time'] = current_time

        logger.info(f"å·²å‘é€å¤šæ¨¡æ€AIå®æ—¶åé¦ˆåˆ°ä¼šè¯ {session_id}")

    except Exception as e:
        logger.error(f"ç”Ÿæˆå®æ—¶åé¦ˆå¤±è´¥: {e}")
        import traceback
        logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")

async def start_realtime_feedback_timer(session_id: str):
    """å¯åŠ¨å®æ—¶åé¦ˆå®šæ—¶å™¨"""
    import asyncio

    try:
        while True:
            session = interview_manager.get_session(session_id)
            if not session:
                logger.info(f"ä¼šè¯ {session_id} ä¸å­˜åœ¨ï¼Œåœæ­¢å®æ—¶åé¦ˆå®šæ—¶å™¨")
                break

            # æ¯10ç§’å‘é€ä¸€æ¬¡å®æ—¶åé¦ˆ
            await asyncio.sleep(10)
            await generate_realtime_feedback(session_id, None)

    except Exception as e:
        logger.error(f"å®æ—¶åé¦ˆå®šæ—¶å™¨å¼‚å¸¸: {e}")

async def generate_and_serve_next_question(session_id: str):
    """ç”Ÿæˆä¸‹ä¸€ä¸ªé—®é¢˜å¹¶å°†å…¶è§†é¢‘URLæä¾›ç»™å‰ç«¯"""
    session = interview_manager.get_session(session_id)
    if not session:
        logger.error(f"æ— æ³•ç”Ÿæˆä¸‹ä¸€ä¸ªé—®é¢˜ï¼šæœªæ‰¾åˆ°ä¼šè¯ {session_id}")
        return

    spark_serv = session['services']['spark']
    avatar_serv = session['services']['avatar']

    # è·å–é¢è¯•é…ç½®å’Œåå¥½è®¾ç½®
    interview_config = session.get('context', {}).get('interview_config', {})
    interview_preferences = session.get('context', {}).get('interview_preferences', {})

    # è®°å½•é…ç½®ä¿¡æ¯ï¼ˆä½¿ç”¨å˜é‡é¿å…æœªä½¿ç”¨è­¦å‘Šï¼‰
    logger.debug(f"é¢è¯•é…ç½®: {interview_config.get('interview_mode', 'default')}")

    # 1. æŒ‡ç¤ºSparkç”Ÿæˆä¸‹ä¸€ä¸ªé—®é¢˜ï¼ˆä½¿ç”¨ä¸ªæ€§åŒ–é…ç½®ï¼‰
    next_question_result = await spark_serv.generate_next_question_based_on_history()

    if not next_question_result.get('success'):
        logger.error(f"ä¸ºä¼šè¯ {session_id} ç”Ÿæˆä¸‹ä¸€ä¸ªé—®é¢˜å¤±è´¥: {next_question_result.get('error')}")
        socketio.emit('error', {'message': 'AIæ— æ³•ç”Ÿæˆä¸‹ä¸€ä¸ªé—®é¢˜'}, room=session_id)
        return

    question_data = next_question_result.get('data', {})
    question_content = question_data.get('content', 'ä½ èƒ½å†è¯¦ç»†è¯´æ˜ä¸€ä¸‹å—ï¼Ÿ')
    
    # 2. è°ƒç”¨AvataræœåŠ¡ä¸ºæ–°é—®é¢˜ç”Ÿæˆè§†é¢‘ï¼ˆä½¿ç”¨ä¸ªæ€§åŒ–åå¥½è®¾ç½®ï¼‰
    video_result = avatar_serv.create_avatar_response(
        question_content,
        preferences=interview_preferences
    )

    if not video_result.get('success'):
        logger.error(f"ä¸ºä¼šè¯ {session_id} ç”Ÿæˆè™šæ‹Ÿäººè§†é¢‘å¤±è´¥: {video_result.get('error')}")
        socketio.emit('error', {'message': 'è™šæ‹Ÿäººè§†é¢‘ç”Ÿæˆå¤±è´¥'}, room=session_id)
        return

    video_url = video_result.get('video_url')
    stream_type = video_result.get('stream_type', 'http')

    # 3. å°†æ–°é—®é¢˜çš„è§†é¢‘URLå‘é€ç»™å‰ç«¯
    logger.info(f"ä¸ºä¼šè¯ {session_id} æä¾›æ–°é—®é¢˜è§†é¢‘: {video_url}")
    logger.info(f"æµåª’ä½“ç±»å‹: {stream_type}")
    logger.info(f"ä½¿ç”¨çš„é¢è¯•åå¥½: {interview_preferences}")

    # å‘é€è™šæ‹Ÿäººè§†é¢‘æµä¿¡æ¯
    socketio.emit('avatar_video_stream', {
        'video_url': video_url,
        'stream_type': stream_type,
        'text': question_content,
        'message': video_result.get('message', 'è™šæ‹Ÿäººå“åº”å·²ç”Ÿæˆ')
    }, room=session_id)

    socketio.emit('new_question_video', {
        'video_url': video_url,
        'stream_type': stream_type,
        'question_data': question_data # å°†å®Œæ•´æ•°æ®ï¼ˆåŒ…æ‹¬å‚è€ƒç­”æ¡ˆï¼‰ä¹Ÿå‘ç»™å‰ç«¯
    }, room=session_id)

# é‡å¤çš„handle_start_streamingå‡½æ•°å·²åˆ é™¤

@socketio.on('audio_data')
def handle_audio_data(data):
    """å¤„ç†16kHz PCMéŸ³é¢‘æ•°æ®"""
    try:
        # ä¿®å¤ï¼šä»dataä¸­è·å–session_idï¼Œè€Œä¸æ˜¯ä½¿ç”¨request.sid
        session_id = data.get('session_id')
        if not session_id:
            logger.error("éŸ³é¢‘æ•°æ®å¤„ç†å¤±è´¥: ç¼ºå°‘session_id")
            emit('error', {'message': 'ç¼ºå°‘session_id'})
            return

        # è·å–ä¼šè¯
        session = interview_manager.get_session(session_id)
        if not session:
            logger.warning(f"ä¼šè¯ä¸å­˜åœ¨: {session_id}")
            emit('error', {'message': 'ä¼šè¯ä¸å­˜åœ¨'})
            return

        # å¤„ç†16kHz PCMéŸ³é¢‘æ•°æ®
        audio_base64 = data.get('audio', '')
        is_first_frame = data.get('isFirst', False)

        if is_first_frame:
            logger.info(f"æ”¶åˆ°ç¬¬ä¸€å¸§éŸ³é¢‘æ•°æ®ï¼Œé‡‡æ ·ç‡: {data.get('sampleRate')}, é€šé“æ•°: {data.get('channels')}")

        # ä½¿ç”¨åŒæ­¥æ–¹å¼å¤„ç†éŸ³é¢‘æ•°æ®
        process_audio_data_sync(session_id, audio_base64, is_first_frame)

    except Exception as e:
        logger.exception(f"å¤„ç†éŸ³é¢‘æ•°æ®å¤±è´¥: {e}")
        emit('error', {'message': f'å¤„ç†éŸ³é¢‘æ•°æ®å¤±è´¥: {str(e)}'})

def process_audio_data_sync(session_id: str, audio_base64: str, is_first_frame: bool = False):
    """åŒæ­¥å¤„ç†16kHz PCMéŸ³é¢‘æ•°æ®"""
    try:
        session = interview_manager.get_session(session_id)
        if not session:
            return

        # ç¡®ä¿å®æ—¶æ•°æ®å­˜å‚¨å­˜åœ¨
        if 'realtime_data' not in session:
            session['realtime_data'] = {'transcriptions': [], 'vision_analysis': [], 'audio_analysis': []}

        # è§£ç base64éŸ³é¢‘æ•°æ®
        try:
            import base64
            audio_bytes = base64.b64decode(audio_base64)
            logger.debug(f"è§£ç PCMéŸ³é¢‘æ•°æ®ï¼Œå¤§å°: {len(audio_bytes)} bytes")
        except Exception as e:
            logger.error(f"PCMéŸ³é¢‘æ•°æ®è§£ç å¤±è´¥: {e}")
            return

        # å¦‚æœæœ‰éŸ³é¢‘æœåŠ¡ï¼Œè¿›è¡Œè¯­éŸ³è½¬å†™
        audio_service = session['services'].get('audio')
        if audio_service:
            try:
                # è°ƒç”¨éŸ³é¢‘æœåŠ¡è¿›è¡Œè½¬å†™ï¼ˆæŒ‰RTASRåè®®ï¼‰
                transcription_result = audio_service.transcribe_audio_chunk_sync(audio_bytes, is_first_frame)
                
                # åªæœ‰å½“æœ‰è½¬å†™ç»“æœæ—¶æ‰å¤„ç†
                if transcription_result and transcription_result.get('text'):
                    # å­˜å‚¨è½¬å†™ç»“æœ
                    session['realtime_data']['transcriptions'].append({
                        'text': transcription_result['text'],
                        'timestamp': time.time(),
                        'confidence': transcription_result.get('confidence', 0.8),
                        'is_final': transcription_result.get('is_final', False)
                    })

                    # ä¿æŒæœ€è¿‘50æ¡è®°å½•
                    if len(session['realtime_data']['transcriptions']) > 50:
                        session['realtime_data']['transcriptions'] = session['realtime_data']['transcriptions'][-50:]

                    logger.info(f"ä¼šè¯ {session_id} è¯­éŸ³è½¬å†™: {transcription_result['text'][:50]}...")
                    
                    # è§¦å‘å®æ—¶åé¦ˆç”Ÿæˆï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰
                    generate_realtime_feedback_sync(session_id)
                else:
                    # å¦‚æœæ²¡æœ‰è½¬å†™ç»“æœï¼ˆè®¯é£å¼‚æ­¥å¤„ç†ï¼‰ï¼Œåªå‘é€éŸ³é¢‘æ•°æ®
                    logger.debug(f"ä¼šè¯ {session_id} PCMéŸ³é¢‘æ•°æ®å·²å‘é€åˆ°è®¯é£ï¼Œç­‰å¾…å¼‚æ­¥è½¬å†™ç»“æœ")
                    
            except Exception as e:
                logger.error(f"éŸ³é¢‘è½¬å†™å¤±è´¥: {e}")

        # åŒæ—¶è¿›è¡ŒéŸ³é¢‘åˆ†æ
        if audio_service:
            try:
                analysis_result = audio_service.analyze_audio_chunk_sync(audio_bytes)
                if analysis_result:
                    session['realtime_data']['audio_analysis'].append({
                        'analysis': analysis_result,
                        'timestamp': time.time()
                    })
                    
                    # ä¿æŒæœ€è¿‘20æ¡éŸ³é¢‘åˆ†æè®°å½•
                    if len(session['realtime_data']['audio_analysis']) > 20:
                        session['realtime_data']['audio_analysis'] = session['realtime_data']['audio_analysis'][-20:]
                        
            except Exception as e:
                logger.error(f"éŸ³é¢‘åˆ†æå¤±è´¥: {e}")

    except Exception as e:
        logger.error(f"åŒæ­¥å¤„ç†PCMéŸ³é¢‘æ•°æ®å¤±è´¥: {e}")

def generate_realtime_feedback_sync(session_id: str):
    """åŒæ­¥ç”Ÿæˆå®æ—¶åé¦ˆ"""
    try:
        session = interview_manager.get_session(session_id)
        if not session:
            return

        # æ£€æŸ¥åé¦ˆé—´éš”ï¼ˆé¿å…é‡å¤å‘é€ï¼‰
        last_feedback_time = session.get('last_feedback_time', 0)
        current_time = time.time()
        
        # å¦‚æœè·ç¦»ä¸Šæ¬¡åé¦ˆæ—¶é—´å°‘äº3ç§’ï¼Œè·³è¿‡
        if current_time - last_feedback_time < 3:
            logger.debug(f"ä¼šè¯ {session_id} åé¦ˆé—´éš”å¤ªçŸ­ï¼Œè·³è¿‡")
            return

        # è·å–å®æ—¶æ•°æ®
        realtime_data = session.get('realtime_data', {})
        current_question = session.get('context', {}).get('current_question_data', {})
        interview_config = session.get('context', {}).get('interview_config', {})

        # è·å–æœ€è¿‘çš„è½¬å†™æ–‡æœ¬ï¼ˆæœ€è¿‘30ç§’ï¼‰
        recent_transcriptions = realtime_data.get('transcriptions', [])
        recent_text = " ".join([
            t['text'] for t in recent_transcriptions
            if current_time - t['timestamp'] <= 30
        ])

        # è·å–æœ€è¿‘çš„è§†è§‰åˆ†æç»“æœ
        recent_vision = realtime_data.get('vision_analysis', [])
        latest_vision = recent_vision[-1] if recent_vision else None

        # è·å–æœ€è¿‘çš„è¯­éŸ³åˆ†æç»“æœ
        recent_audio_analysis = realtime_data.get('audio_analysis', [])
        latest_audio_analysis = recent_audio_analysis[-1] if recent_audio_analysis else None

        # å¦‚æœæ²¡æœ‰æ–°æ•°æ®ï¼Œè·³è¿‡åé¦ˆ
        if not recent_text and not latest_vision and not latest_audio_analysis:
            logger.debug(f"ä¼šè¯ {session_id} æ²¡æœ‰æ–°æ•°æ®ï¼Œè·³è¿‡åé¦ˆç”Ÿæˆ")
            return

        # ç”ŸæˆåŸºäºå®é™…æ•°æ®çš„åé¦ˆ
        feedback = {
            'audio': "è¯­é€Ÿé€‚ä¸­ï¼Œè¡¨è¾¾æ¸…æ™°",
            'behavior': "è¡¨ç°è‡ªç„¶ï¼Œäº’åŠ¨è‰¯å¥½",
            'technical': recent_text[:100] + "..." if len(recent_text) > 100 else recent_text or "ç­‰å¾…å›ç­”å†…å®¹åˆ†æ...",
            'stress': "æƒ…ç»ªç¨³å®šï¼Œåº”å¯¹ä»å®¹"
        }

        # ä½¿ç”¨è·å–åˆ°çš„æ•°æ®ï¼ˆé¿å…æœªä½¿ç”¨å˜é‡è­¦å‘Šï¼‰
        if current_question.get('content'):
            logger.debug(f"å½“å‰é—®é¢˜: {current_question['content'][:50]}...")
        if interview_config.get('interview_mode'):
            logger.debug(f"é¢è¯•æ¨¡å¼: {interview_config['interview_mode']}")

        # æ›´æ–°æœ€ååé¦ˆæ—¶é—´
        session['last_feedback_time'] = current_time

        # å‘é€å®æ—¶åé¦ˆåˆ°å‰ç«¯
        socketio.emit('realtime_feedback', {
            'success': True,
            'feedback': feedback,
            'timestamp': current_time,
            'ai_generated': True,
            'analyzing': False,
            'data_sources': {
                'has_transcription': bool(recent_text),
                'has_vision': bool(latest_vision),
                'has_audio_analysis': bool(latest_audio_analysis)
            }
        }, room=session_id)

        logger.info(f"å·²å‘é€åŒæ­¥å®æ—¶åé¦ˆåˆ°ä¼šè¯ {session_id}")

    except Exception as e:
        logger.error(f"åŒæ­¥ç”Ÿæˆå®æ—¶åé¦ˆå¤±è´¥: {e}")

@socketio.on('generate_next_question')
def handle_generate_next_question(data):
        """å¤„ç†ç”Ÿæˆä¸‹ä¸€é¢˜çš„WebSocketè¯·æ±‚"""
        try:
            session_id = data.get('session_id')
            logger.info(f"WebSocketè¯·æ±‚ç”Ÿæˆä¸‹ä¸€é¢˜ï¼Œä¼šè¯ID: {session_id}")

            if not session_id:
                emit('error', {'message': 'ç¼ºå°‘session_id'})
                return

            # è·å–ä¼šè¯
            session = interview_manager.get_session(session_id)
            if not session:
                emit('error', {'message': 'æ— æ•ˆçš„ä¼šè¯ID'})
                return

            # å¼‚æ­¥ç”Ÿæˆä¸‹ä¸€ä¸ªé—®é¢˜
            import asyncio
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)

            try:
                loop.run_until_complete(generate_next_question_async(session_id, session))
            finally:
                loop.close()

        except Exception as e:
            logger.exception(f"ç”Ÿæˆä¸‹ä¸€é¢˜å¤±è´¥: {e}")
            emit('error', {'message': f'ç”Ÿæˆä¸‹ä¸€é¢˜å¤±è´¥: {str(e)}'})

@socketio.on('user_answer')
def handle_user_answer(data):
        """å¤„ç†ç”¨æˆ·ç­”æ¡ˆ"""
        try:
            session_id = data.get('session_id')
            answer = data.get('answer', '')

            logger.info(f"æ”¶åˆ°ç”¨æˆ·ç­”æ¡ˆï¼Œä¼šè¯ID: {session_id}")
            logger.info(f"ç­”æ¡ˆå†…å®¹: {answer[:100]}...")

            if not session_id:
                emit('error', {'message': 'ç¼ºå°‘session_id'})
                return

            # è·å–ä¼šè¯
            session = interview_manager.get_session(session_id)
            if not session:
                emit('error', {'message': 'æ— æ•ˆçš„ä¼šè¯ID'})
                return

            # å°†ç­”æ¡ˆæ·»åŠ åˆ°å¯¹è¯å†å²
            session['services']['spark'].add_to_conversation('user', answer)

            # ç”ŸæˆAIåé¦ˆ
            feedback_prompt = f"è¯·å¯¹ä»¥ä¸‹å›ç­”ç»™å‡ºç®€çŸ­çš„ä¸“ä¸šåé¦ˆï¼ˆ1-2å¥è¯ï¼‰ï¼š{answer}"
            feedback_result = session['services']['spark'].chat_completion_http(
                [{"role": "user", "content": feedback_prompt}],
                "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é¢è¯•å®˜ï¼Œè¯·ç»™å‡ºå»ºè®¾æ€§çš„åé¦ˆã€‚"
            )

            ai_feedback = "å›ç­”å¾—ä¸é”™ï¼Œè¯·ç»§ç»­ã€‚"
            if feedback_result.get('success'):
                ai_feedback = feedback_result.get('message', ai_feedback)

            # å‘é€AIåé¦ˆ
            emit('ai_feedback', {
                'success': True,
                'feedback': ai_feedback,
                'session_id': session_id
            })

            logger.info(f"ğŸ¤– AIåé¦ˆ: {ai_feedback}")

        except Exception as e:
            logger.exception(f"å¤„ç†ç”¨æˆ·ç­”æ¡ˆå¤±è´¥: {e}")
            emit('error', {'message': f'å¤„ç†ç”¨æˆ·ç­”æ¡ˆå¤±è´¥: {str(e)}'})

# é‡å¤çš„å‡½æ•°å·²åˆ é™¤ï¼Œä½¿ç”¨ä¸Šé¢çš„asyncç‰ˆæœ¬

async def generate_next_question_async(session_id: str, session: dict):
    """å¼‚æ­¥ç”Ÿæˆä¸‹ä¸€ä¸ªé—®é¢˜"""
    try:
        # ä½¿ç”¨AIç”Ÿæˆä¸‹ä¸€ä¸ªé—®é¢˜
        result = await session['services']['spark'].generate_next_question_based_on_history()

        if result.get('success'):
            question_data = result['data']

            # å°†AIé—®é¢˜æ·»åŠ åˆ°å¯¹è¯å†å²
            session['services']['spark'].add_to_conversation('assistant', question_data['content'])

            # æ›´æ–°ä¼šè¯çŠ¶æ€
            session['context']['current_question_number'] = session['context'].get('current_question_number', 1) + 1
            session['context']['current_question_data'] = question_data

            # ç”Ÿæˆè™šæ‹Ÿäººè§†é¢‘
            video_url = None
            if session.get('preferences', {}).get('enable_avatar', True):
                avatar_serv = session['services'].get('avatar')
                if avatar_serv:
                    video_result = avatar_serv.create_avatar_response(
                        question_data['content'],
                        preferences=session.get('preferences', {})
                    )
                    if video_result.get('success'):
                        video_url = video_result.get('video_url')

            # é€šè¿‡WebSocketå‘é€æ–°é—®é¢˜
            socketio.emit('new_question_video', {
                'success': True,
                'question': {
                    'id': session['context']['current_question_number'],
                    'content': question_data['content'],
                    'type': question_data['type'],
                    'difficulty': 'medium'
                },
                'question_number': session['context']['current_question_number'],
                'total_questions': 10,
                'video_url': video_url,
                'finished': session['context']['current_question_number'] >= 10
            }, room=session_id)

        else:
            socketio.emit('error', {
                'message': f'AIç”Ÿæˆé—®é¢˜å¤±è´¥: {result.get("error")}'
            }, room=session_id)

    except Exception as e:
        logger.exception(f"å¼‚æ­¥ç”Ÿæˆä¸‹ä¸€é¢˜å¤±è´¥: {e}")
        socketio.emit('error', {
            'message': f'ç”Ÿæˆä¸‹ä¸€é¢˜å¤±è´¥: {str(e)}'
        }, room=session_id)

# æ·»åŠ æ–°çš„WebSocketäº‹ä»¶å¤„ç†å™¨
@socketio.on('screenshot_data')
def handle_screenshot_data(data):
    """å¤„ç†å‰ç«¯å‘é€çš„æˆªå›¾æ•°æ®"""
    try:
        session_id = data.get('session_id')
        image_data = data.get('image_data')  # base64ç¼–ç çš„å›¾ç‰‡æ•°æ®

        session = interview_manager.get_session(session_id)
        if not session:
            emit('error', {'message': 'ä¼šè¯ä¸å­˜åœ¨'})
            return

        # å¼‚æ­¥å¤„ç†è§†è§‰åˆ†æ
        socketio.start_background_task(process_screenshot_analysis, session_id, image_data)

    except Exception as e:
        logger.error(f"å¤„ç†æˆªå›¾æ•°æ®å¤±è´¥: {e}")
        emit('error', {'message': f'å¤„ç†æˆªå›¾æ•°æ®å¤±è´¥: {str(e)}'})

@socketio.on('audio_chunk')
def handle_audio_chunk(data):
    """å¤„ç†å‰ç«¯å‘é€çš„éŸ³é¢‘å—æ•°æ®"""
    try:
        session_id = data.get('session_id')
        audio_data = data.get('audio_data')  # base64ç¼–ç çš„éŸ³é¢‘æ•°æ®

        session = interview_manager.get_session(session_id)
        if not session:
            emit('error', {'message': 'ä¼šè¯ä¸å­˜åœ¨'})
            return

        # å¼‚æ­¥å¤„ç†éŸ³é¢‘åˆ†æ
        socketio.start_background_task(process_audio_analysis, session_id, audio_data)

    except Exception as e:
        logger.error(f"å¤„ç†éŸ³é¢‘å—å¤±è´¥: {e}")
        emit('error', {'message': f'å¤„ç†éŸ³é¢‘å—å¤±è´¥: {str(e)}'})

def process_screenshot_analysis(session_id: str, image_data: str):
    """å¤„ç†æˆªå›¾çš„è§†è§‰åˆ†æï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰"""
    try:
        session = interview_manager.get_session(session_id)
        if not session:
            return

        vision_service = session['services'].get('vision')
        if not vision_service:
            logger.warning(f"ä¼šè¯ {session_id} æ²¡æœ‰è§†è§‰æœåŠ¡")
            return

        # ç¡®ä¿realtime_dataå­˜åœ¨
        if 'realtime_data' not in session:
            session['realtime_data'] = {'transcriptions': [], 'vision_analysis': [], 'audio_analysis': []}

        # ç¡®ä¿vision_resultsé”®å­˜åœ¨
        if 'vision_results' not in session['realtime_data']:
            session['realtime_data']['vision_results'] = []

        # è°ƒç”¨è§†è§‰åˆ†ææœåŠ¡ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰
        try:
            # è§£ç base64å›¾ç‰‡æ•°æ®
            import base64
            image_bytes = base64.b64decode(image_data.split(',')[1] if ',' in image_data else image_data)

            # ä½¿ç”¨åŒæ­¥æ–¹æ³•åˆ†æå›¾ç‰‡
            analysis_result = vision_service.analyze_expression_xunfei(image_bytes)

            if analysis_result:
                # å­˜å‚¨è§†è§‰åˆ†æç»“æœ
                vision_data = {
                    'result': analysis_result,
                    'timestamp': time.time(),
                    'summary': analysis_result.get('emotion', 'æ— æ³•åˆ†æ')
                }

                session['realtime_data']['vision_results'].append(vision_data)

                # ä¿æŒæœ€è¿‘60ç§’çš„è§†è§‰åˆ†æè®°å½•
                current_time = time.time()
                session['realtime_data']['vision_results'] = [
                    v for v in session['realtime_data']['vision_results']
                    if current_time - v['timestamp'] <= 60
                ]

                logger.info(f"ä¼šè¯ {session_id} è§†è§‰åˆ†æå®Œæˆ: {analysis_result.get('emotion', '')}")
            else:
                logger.warning(f"ä¼šè¯ {session_id} è§†è§‰åˆ†æè¿”å›ç©ºç»“æœ")

        except Exception as decode_error:
            logger.error(f"å›¾ç‰‡è§£ç æˆ–åˆ†æå¤±è´¥: {decode_error}")

    except Exception as e:
        logger.error(f"å¤„ç†æˆªå›¾åˆ†æå¤±è´¥: {e}")

def process_audio_analysis(session_id: str, audio_data: str):
    """å¤„ç†éŸ³é¢‘çš„è¯­éŸ³åˆ†æï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰"""
    try:
        session = interview_manager.get_session(session_id)
        if not session:
            return

        audio_service = session['services'].get('audio')
        if not audio_service:
            logger.warning(f"ä¼šè¯ {session_id} æ²¡æœ‰éŸ³é¢‘æœåŠ¡")
            return

        # ç¡®ä¿realtime_dataå­˜åœ¨
        if 'realtime_data' not in session:
            session['realtime_data'] = {'transcriptions': [], 'vision_analysis': [], 'audio_analysis': []}

        # è°ƒç”¨éŸ³é¢‘åˆ†ææœåŠ¡ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰
        try:
            # è§£ç base64éŸ³é¢‘æ•°æ®
            import base64
            audio_bytes = base64.b64decode(audio_data)

            # ä½¿ç”¨åŒæ­¥æ–¹æ³•åˆ†æéŸ³é¢‘
            analysis_result = audio_service.analyze_audio_chunk_sync(audio_bytes)

            if analysis_result:
                # å­˜å‚¨éŸ³é¢‘åˆ†æç»“æœ
                audio_analysis_data = {
                    'result': analysis_result,
                    'timestamp': time.time(),
                    'summary': analysis_result.get('summary', 'æ— æ³•åˆ†æ')
                }

                session['realtime_data']['audio_analysis'].append(audio_analysis_data)

                # ä¿æŒæœ€è¿‘60ç§’çš„éŸ³é¢‘åˆ†æè®°å½•
                current_time = time.time()
                session['realtime_data']['audio_analysis'] = [
                    a for a in session['realtime_data']['audio_analysis']
                    if current_time - a['timestamp'] <= 60
                ]

                logger.info(f"ä¼šè¯ {session_id} éŸ³é¢‘åˆ†æå®Œæˆ: {analysis_result.get('summary', '')[:50]}...")
            else:
                logger.warning(f"ä¼šè¯ {session_id} éŸ³é¢‘åˆ†æè¿”å›ç©ºç»“æœ")

        except Exception as decode_error:
            logger.error(f"éŸ³é¢‘è§£ç æˆ–åˆ†æå¤±è´¥: {decode_error}")

    except Exception as e:
        logger.error(f"å¤„ç†éŸ³é¢‘åˆ†æå¤±è´¥: {e}")