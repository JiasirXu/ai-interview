#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
äººè„¸æ£€æµ‹ + è¡¨æƒ…è¯†åˆ« WebAPI è°ƒç”¨
"""

import requests
import base64
import hashlib
import json
import time
from typing import Dict, Any, Optional, List
from loguru import logger
from flask import current_app
import threading
import asyncio
from concurrent.futures import ThreadPoolExecutor

# æ¡ä»¶å¯¼å…¥æˆªå›¾ç›¸å…³æ¨¡å—
try:
    import pyautogui
    import io
    from PIL import Image
    SCREENSHOT_AVAILABLE = True
except ImportError:
    SCREENSHOT_AVAILABLE = False
    logger.warning("pyautoguiæˆ–PILæœªå®‰è£…ï¼Œæˆªå›¾åŠŸèƒ½å°†ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")

class VisionService:
    """è§†è§‰æœåŠ¡"""
    
    def __init__(self, config=None):
        self.config = config
        self.face_config = None
        self.face_detection_url = None
        self.emotion_recognition_url = None
        self.executor = ThreadPoolExecutor(max_workers=5)
        self.active_sessions = {}
        self.emotion_history = {}
        self._initialized = False
        self.appid = None
        self.apisecret = None
        self.apikey = None
    
    def _ensure_initialized(self):
        """ç¡®ä¿æœåŠ¡å·²åˆå§‹åŒ–"""
        if not self._initialized:
            if self.config is None:
                from flask import current_app
                self.config = current_app.config.get('XUNFEI_CONFIG', {})
            
            # ä»ä¸»é…ç½®ä¸­è·å–é€šç”¨è®¤è¯ä¿¡æ¯
            self.appid = self.config.get('APPID')
            self.apikey = self.config.get('APIKey')
            self.apisecret = self.config.get('APISecret')

            self.face_config = self.config.get('FACE', {})
            self.face_detection_url = self.face_config.get('DETECTION_URL')
            self.emotion_recognition_url = self.face_config.get('EXPRESSION_URL')
            self._initialized = True
    
    def _get_face_detection_headers(self) -> Dict[str, str]:
        """è·å–äººè„¸æ£€æµ‹APIçš„è®¤è¯headers"""
        self._ensure_initialized()
        
        # æ ¹æ®æ–‡æ¡£ï¼Œäººè„¸æ£€æµ‹WebAPIéœ€è¦ç‰¹å®šçš„è®¤è¯å¤´
        # https://www.xfyun.cn/doc/face/xf-face-detect/API.html
        x_time = str(int(time.time()))
        
        # 1. åˆ›å»º x-param
        param_dict = {"sdk_version": "1.0"}
        param_base64 = base64.b64encode(json.dumps(param_dict).encode('utf-8')).decode('utf-8')
        
        # 2. åˆ›å»º x-check-sum
        checksum_str = self.apikey + x_time + param_base64
        checksum = hashlib.md5(checksum_str.encode('utf-8')).hexdigest()

        return {
            'Content-Type': 'application/x-www-form-urlencoded; charset=utf-8',
            'X-Appid': self.appid,
            'X-CurTime': x_time,
            'X-Param': param_base64,
            'X-CheckSum': checksum
        }
    
    def detect_faces(self, image_data: bytes) -> Dict[str, Any]:
        """
        äººè„¸æ£€æµ‹
        
        Args:
            image_data: å›¾ç‰‡æ•°æ®
            
        Returns:
            æ£€æµ‹ç»“æœ
        """
        self._ensure_initialized()
        try:
            image_base64 = base64.b64encode(image_data).decode('utf-8')
            
            payload = {
                "image": image_base64,
                # æ ¹æ®æ–‡æ¡£ï¼Œattributeå’Œlandmarkæ˜¯å¸ƒå°”å€¼
                "attribute": 1,
                "landmark": 1
            }
            
            response = requests.post(
                self.face_detection_url,
                headers=self._get_face_detection_headers(),
                data=payload,
                timeout=15
            )
            
            if response.status_code == 200:
                result = response.json()
                if result.get('code') == 0:
                    return {
                        'success': True,
                        'data': result.get('data', {}),
                        'face_count': len(result.get('data', {}).get('face_list', [])),
                        'timestamp': time.time()
                    }
                else:
                    logger.error(f"äººè„¸æ£€æµ‹APIè¿”å›é”™è¯¯: {result}")
                    return {
                        'success': False,
                        'error': f"APIé”™è¯¯: {result.get('desc', 'æœªçŸ¥APIé”™è¯¯')}"
                    }
            else:
                logger.error(f"äººè„¸æ£€æµ‹å¤±è´¥: {response.status_code}, {response.text}")
                return {
                    'success': False,
                    'error': f"HTTPé”™è¯¯: {response.status_code}"
                }
                
        except Exception as e:
            logger.error(f"äººè„¸æ£€æµ‹å¼‚å¸¸: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def recognize_emotion(self, image_data: bytes) -> Dict[str, Any]:
        """
        è¡¨æƒ…è¯†åˆ«
        
        Args:
            image_data: å›¾ç‰‡æ•°æ®
            
        Returns:
            è¯†åˆ«ç»“æœ
        """
        self._ensure_initialized()
        try:
            image_base64 = base64.b64encode(image_data).decode('utf-8')
            
            payload = {
                "appid": self.appid,
                "image": image_base64,
                "scene": "default", # 'default' åœºæ™¯æ›´é€šç”¨
            }
            
            # è¡¨æƒ…åˆ†æAPIä½¿ç”¨ä¸åŒçš„è®¤è¯æ–¹å¼ï¼Œé€šå¸¸æ˜¯ç­¾ååœ¨è¯·æ±‚ä½“å†…
            # è¿™é‡Œæˆ‘ä»¬å‡è®¾å®ƒä¸éœ€è¦ç‰¹æ®Šçš„headerï¼Œå‡­è¯åœ¨bodyä¸­
            response = requests.post(
                self.emotion_recognition_url,
                headers={'Content-Type': 'application/x-www-form-urlencoded'},
                data=payload,
                timeout=15
            )
            
            if response.status_code == 200:
                result = response.json()
                # æ ¹æ®æ–‡æ¡£ï¼Œcodeä¸º0è¡¨ç¤ºæˆåŠŸ
                if result.get('code') == 0:
                    return {
                        'success': True,
                        'data': result.get('data', {}),
                        'timestamp': time.time()
                    }
                else:
                    logger.error(f"è¡¨æƒ…è¯†åˆ«APIè¿”å›é”™è¯¯: {result}")
                    return {
                        'success': False,
                        'error': f"APIé”™è¯¯: {result.get('desc', 'æœªçŸ¥APIé”™è¯¯')}"
                    }
            else:
                logger.error(f"è¡¨æƒ…è¯†åˆ«å¤±è´¥: {response.status_code}, {response.text}")
                return {
                    'success': False,
                    'error': f"HTTPé”™è¯¯: {response.status_code}"
                }
                
        except Exception as e:
            logger.error(f"è¡¨æƒ…è¯†åˆ«å¼‚å¸¸: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def analyze_face_and_emotion(self, image_data: bytes) -> Dict[str, Any]:
        """
        ç»¼åˆåˆ†æäººè„¸å’Œè¡¨æƒ…
        
        Args:
            image_data: å›¾ç‰‡æ•°æ®
            
        Returns:
            åˆ†æç»“æœ
        """
        try:
            # å¹¶è¡Œè°ƒç”¨äººè„¸æ£€æµ‹å’Œè¡¨æƒ…è¯†åˆ«
            face_future = self.executor.submit(self.detect_faces, image_data)
            emotion_future = self.executor.submit(self.recognize_emotion, image_data)
            
            # ç­‰å¾…ç»“æœ
            face_result = face_future.result(timeout=15)
            emotion_result = emotion_future.result(timeout=15)
            
            # ç»¼åˆç»“æœ
            analysis = {
                'success': True,
                'timestamp': time.time(),
                'face_detection': face_result,
                'emotion_recognition': emotion_result
            }
            
            # æå–å…³é”®ä¿¡æ¯
            if face_result['success'] and emotion_result.get('success', False): # ç¡®ä¿emotion_resultä¹ŸæˆåŠŸ
                analysis['summary'] = self._extract_emotion_summary(face_result, emotion_result)
            elif not face_result['success']:
                analysis['success'] = False
                analysis['error'] = face_result.get('error', 'äººè„¸æ£€æµ‹å¤±è´¥')
            else:
                analysis['summary'] = self._extract_emotion_summary(face_result, {}) # å³ä½¿è¡¨æƒ…è¯†åˆ«å¤±è´¥ï¼Œä¹Ÿå°è¯•æå–éƒ¨åˆ†ä¿¡æ¯
            
            return analysis
            
        except Exception as e:
            logger.error(f"ç»¼åˆåˆ†æå¤±è´¥: {e}")
            return {
                'success': False,
                'error': str(e)
            }

    def analyze_expression_xunfei(self, image_data: bytes) -> Optional[Dict[str, Any]]:
        """
        ä½¿ç”¨è®¯é£äººè„¸è¡¨æƒ…åˆ†æAPIåˆ†æè¡¨æƒ…

        Args:
            image_data: å›¾ç‰‡æ•°æ®

        Returns:
            åˆ†æç»“æœ
        """
        try:
            # ç¡®ä¿åœ¨Flaskåº”ç”¨ä¸Šä¸‹æ–‡ä¸­åˆå§‹åŒ–
            try:
                self._ensure_initialized()
            except RuntimeError as e:
                if "application context" in str(e):
                    # å¦‚æœæ²¡æœ‰åº”ç”¨ä¸Šä¸‹æ–‡ï¼Œå°è¯•è·å–
                    from flask import current_app
                    if current_app:
                        with current_app.app_context():
                            self._ensure_initialized()
                    else:
                        logger.error("æ— æ³•è·å–Flaskåº”ç”¨ä¸Šä¸‹æ–‡")
                        return None
                else:
                    raise

            # è®¯é£äººè„¸è¡¨æƒ…åˆ†æAPIåœ°å€
            url = "http://tupapi.xfyun.cn/v1/expression"

            # æ„å»ºè¯·æ±‚å¤´ - æŒ‰ç…§è®¯é£APIè§„èŒƒ
            headers = self._build_xunfei_expression_headers(image_data)

            # å‘é€è¯·æ±‚ - å›¾ç‰‡æ•°æ®æ”¾åœ¨è¯·æ±‚ä½“ä¸­
            response = requests.post(url, headers=headers, data=image_data, timeout=30)

            if response.status_code == 200:
                result = response.json()
                logger.info(f"è®¯é£äººè„¸è¡¨æƒ…åˆ†ææˆåŠŸ: {result}")
                return self._parse_expression_result(result)
            else:
                logger.error(f"è®¯é£äººè„¸è¡¨æƒ…åˆ†æå¤±è´¥: {response.status_code}, {response.text}")
                return None

        except Exception as e:
            logger.error(f"è®¯é£è¡¨æƒ…åˆ†æå¼‚å¸¸: {e}")
            return None

    def _build_xunfei_expression_headers(self, image_data: bytes) -> Dict[str, str]:
        """æ„å»ºè®¯é£äººè„¸è¡¨æƒ…åˆ†æAPIè¯·æ±‚å¤´"""
        try:
            # å½“å‰UTCæ—¶é—´æˆ³
            cur_time = str(int(time.time()))

            # ä¸šåŠ¡å‚æ•°
            param = {
                "image_name": "screenshot.jpg"
            }
            param_str = json.dumps(param)

            # Base64ç¼–ç å‚æ•°
            x_param = base64.b64encode(param_str.encode('utf-8')).decode('utf-8')

            # è®¡ç®—ç­¾å - MD5(APIKey + X-CurTime + X-Param)
            sign_str = self.apikey + cur_time + x_param
            x_checksum = hashlib.md5(sign_str.encode('utf-8')).hexdigest()

            # æ„å»ºè¯·æ±‚å¤´
            headers = {
                'X-Appid': self.appid,
                'X-CurTime': cur_time,
                'X-Param': x_param,
                'X-CheckSum': x_checksum,
                'Content-Type': 'application/octet-stream'
            }

            return headers

        except Exception as e:
            logger.error(f"æ„å»ºè®¯é£è¡¨æƒ…åˆ†æè¯·æ±‚å¤´å¤±è´¥: {e}")
            return {}

    def _parse_expression_result(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """è§£æè®¯é£äººè„¸è¡¨æƒ…åˆ†æç»“æœ"""
        try:
            if result.get('code') != 0:
                logger.error(f"è®¯é£è¡¨æƒ…åˆ†æè¿”å›é”™è¯¯: {result}")
                return {}

            data = result.get('data', {})
            file_list = data.get('fileList', [])

            if not file_list:
                return {'emotion': 'unknown', 'confidence': 0.0}

            # è·å–ç¬¬ä¸€ä¸ªæ–‡ä»¶çš„åˆ†æç»“æœ
            first_file = file_list[0]
            label = first_file.get('label', -1)
            rate = first_file.get('rate', 0.0)

            # è¡¨æƒ…æ ‡ç­¾æ˜ å°„
            emotion_map = {
                0: 'other',      # å…¶ä»–(éäººè„¸è¡¨æƒ…å›¾ç‰‡)
                1: 'other_expression',  # å…¶ä»–è¡¨æƒ…
                2: 'joy',        # å–œæ‚¦
                3: 'anger',      # æ„¤æ€’
                4: 'sadness',    # æ‚²ä¼¤
                5: 'fear',       # æƒŠæ
                6: 'disgust',    # åŒæ¶
                7: 'neutral'     # ä¸­æ€§
            }

            emotion = emotion_map.get(label, 'unknown')

            parsed_result = {
                'emotion': emotion,
                'confidence': rate,
                'label': label,
                'review': first_file.get('review', False),
                'raw_result': result
            }

            logger.info(f"è§£æè¡¨æƒ…ç»“æœ: æƒ…ç»ª={emotion}, ç½®ä¿¡åº¦={rate:.3f}")
            return parsed_result

        except Exception as e:
            logger.error(f"è§£æè¡¨æƒ…åˆ†æç»“æœå¼‚å¸¸: {e}")
            return {'emotion': 'unknown', 'confidence': 0.0}
    
    def _extract_emotion_summary(self, face_result: Dict[str, Any], emotion_result: Dict[str, Any]) -> Dict[str, Any]:
        """æå–è¡¨æƒ…æ‘˜è¦"""
        summary = {
            'confidence_level': 'low',
            'dominant_emotion': 'neutral',
            'attention_level': 'medium',
            'engagement_score': 0.5
        }
        
        try:
            # ä»äººè„¸æ£€æµ‹ç»“æœä¸­æå–ä¿¡æ¯
            faces = face_result.get('data', {}).get('face_list', [])
            if faces:
                face = faces[0]  # å–ç¬¬ä¸€ä¸ªäººè„¸
                
                # æå–å§¿æ€ä¿¡æ¯
                pose = face.get('location', {})
                if pose:
                    # è®¡ç®—æ³¨æ„åŠ›æ°´å¹³ï¼ˆç®€åŒ–ç‰ˆï¼‰
                    # å‡è®¾æ­£è„¸è§’åº¦ä¸º0ï¼Œåç¦»è§’åº¦è¶Šå¤§æ³¨æ„åŠ›è¶Šä½
                    # roll, pitch, yaw èŒƒå›´é€šå¸¸åœ¨-90åˆ°90ä¹‹é—´
                    head_pose_score = 1.0 - (abs(pose.get('pitch', 0)) + abs(pose.get('yaw', 0))) / 180.0
                    summary['attention_level'] = 'high' if head_pose_score > 0.85 else 'medium' if head_pose_score > 0.6 else 'low'
            
            # ä»è¡¨æƒ…è¯†åˆ«ç»“æœä¸­æå–ä¿¡æ¯
            emotion_data = emotion_result.get('data', {})
            if emotion_data:
                # è¡¨æƒ…APIè¿”å›çš„æ˜¯å„ç±»æƒ…ç»ªçš„ç½®ä¿¡åº¦
                emotion_list = emotion_data.get('expression', [])
                if emotion_list:
                    dominant_emotion = max(emotion_list, key=lambda x: x.get('confidence', 0))
                    summary['dominant_emotion'] = dominant_emotion.get('type', 'neutral')
                    confidence = dominant_emotion.get('confidence', 0) / 100.0 # è½¬æ¢ä¸º0-1
                    summary['confidence_level'] = 'high' if confidence > 0.7 else 'medium' if confidence > 0.4 else 'low'
                    
                    # è®¡ç®—å‚ä¸åº¦åˆ†æ•°
                    positive_emotions = ['happy', 'surprised']
                    negative_emotions = ['sad', 'angry', 'fear', 'disgust']
                    
                    emotion_name = summary['dominant_emotion']
                    if emotion_name in positive_emotions:
                        summary['engagement_score'] = 0.7 + (confidence * 0.3) # åŸºç¡€åˆ†+ç½®ä¿¡åº¦åŠ æƒ
                    elif emotion_name in negative_emotions:
                        summary['engagement_score'] = 0.4 - (confidence * 0.3)
                    else: # neutral
                        summary['engagement_score'] = 0.5
            
        except Exception as e:
            logger.error(f"æå–è¡¨æƒ…æ‘˜è¦å¤±è´¥: {e}")
        
        return summary
    
    def analyze_and_store_emotion(self, session_id: str, image_data: bytes) -> Dict[str, Any]:
        """
        åˆ†æå•å¼ å›¾ç‰‡å¹¶ä¸ºä¼šè¯å­˜å‚¨æƒ…æ„Ÿç»“æœ
        
        Args:
            session_id: ä¼šè¯ID
            image_data: ä»å‰ç«¯å‘é€çš„å›¾ç‰‡æ•°æ®
            
        Returns:
            åˆ†æç»“æœçš„æ‘˜è¦
        """
        self._ensure_initialized()
        
        analysis_result = self.analyze_face_and_emotion(image_data)
        
        if not analysis_result['success']:
            logger.error(f"ä¼šè¯ {session_id} çš„å›¾åƒåˆ†æå¤±è´¥: {analysis_result.get('error')}")
            return analysis_result

        summary = analysis_result.get('summary', {})
        
        # ä¸ºä¼šè¯åˆå§‹åŒ–å†å²è®°å½•
        if session_id not in self.emotion_history:
            self.emotion_history[session_id] = []
        
        # å­˜å‚¨ç»“æœ
        storage_record = {
            'timestamp': time.time(),
            'summary': summary
        }
        self.emotion_history[session_id].append(storage_record)

        # ä¿æŒå†å²è®°å½•ä¸è¶…è¿‡200æ¡
        if len(self.emotion_history[session_id]) > 200:
            self.emotion_history[session_id] = self.emotion_history[session_id][-200:]
            
        logger.info(f"ä¸ºä¼šè¯ {session_id} å­˜å‚¨äº†æ–°çš„æƒ…æ„Ÿåˆ†æç»“æœ: {summary}")
        
        return {
            'success': True,
            'summary': summary
        }

    def start_continuous_monitoring(self, session_id: str, interval: int = 5) -> bool:
        """
        å¼€å§‹æŒç»­ç›‘æ§
        
        Args:
            session_id: ä¼šè¯ID
            interval: ç›‘æ§é—´éš”ï¼ˆç§’ï¼‰
            
        Returns:
            æ˜¯å¦å¯åŠ¨æˆåŠŸ
        """
        try:
            if session_id in self.active_sessions:
                logger.warning(f"ä¼šè¯ {session_id} å·²åœ¨ç›‘æ§ä¸­")
                return False
            
            # åˆ›å»ºç›‘æ§ä»»åŠ¡
            monitor_task = {
                'session_id': session_id,
                'interval': interval,
                'active': True,
                'last_capture': None,
                'results': []
            }
            
            self.active_sessions[session_id] = monitor_task
            self.emotion_history[session_id] = []
            
            # å¯åŠ¨ç›‘æ§ä»»åŠ¡
            threading.Thread(
                target=self._monitoring_loop, 
                args=(session_id,),
                daemon=True
            ).start()
            
            logger.info(f"è§†è§‰ç›‘æ§å·²å¯åŠ¨: {session_id}")
            return True
            
        except Exception as e:
            logger.error(f"å¯åŠ¨è§†è§‰ç›‘æ§å¤±è´¥: {e}")
            return False
    
    def _monitoring_loop(self, session_id: str):
        """ç›‘æ§å¾ªç¯"""
        while self.active_sessions.get(session_id, {}).get('active', False):
            try:
                # è¿™é‡Œéœ€è¦å®ç°æˆªå›¾é€»è¾‘
                # æš‚æ—¶ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
                time.sleep(self.active_sessions[session_id]['interval'])
                
                # æ¨¡æ‹Ÿåˆ†æç»“æœ
                mock_result = {
                    'success': True,
                    'timestamp': time.time(),
                    'summary': {
                        'confidence_level': 'medium',
                        'dominant_emotion': 'neutral',
                        'attention_level': 'high',
                        'engagement_score': 0.7
                    }
                }
                
                # ä¿å­˜ç»“æœ
                self.active_sessions[session_id]['results'].append(mock_result)
                self.emotion_history[session_id].append(mock_result)
                
                # ä¿æŒå†å²è®°å½•ä¸è¶…è¿‡100æ¡
                if len(self.emotion_history[session_id]) > 100:
                    self.emotion_history[session_id] = self.emotion_history[session_id][-100:]
                
            except Exception as e:
                logger.error(f"ç›‘æ§å¾ªç¯å¼‚å¸¸: {e}")
                break
    
    def stop_continuous_monitoring(self, session_id: str) -> bool:
        """
        åœæ­¢æŒç»­ç›‘æ§
        
        Args:
            session_id: ä¼šè¯ID
            
        Returns:
            æ˜¯å¦åœæ­¢æˆåŠŸ
        """
        try:
            if session_id in self.active_sessions:
                self.active_sessions[session_id]['active'] = False
                del self.active_sessions[session_id]
                logger.info(f"è§†è§‰ç›‘æ§å·²åœæ­¢: {session_id}")
                return True
            
            return False
            
        except Exception as e:
            logger.error(f"åœæ­¢è§†è§‰ç›‘æ§å¤±è´¥: {e}")
            return False
    
    def get_monitoring_status(self, session_id: str) -> Dict[str, Any]:
        """è·å–ç›‘æ§çŠ¶æ€"""
        if session_id in self.active_sessions:
            task = self.active_sessions[session_id]
            return {
                'active': task['active'],
                'interval': task['interval'],
                'result_count': len(task['results']),
                'last_capture': task['last_capture']
            }
        else:
            return {
                'active': False,
                'message': 'æœªæ‰¾åˆ°ç›‘æ§ä¼šè¯'
            }
    
    def get_emotion_history(self, session_id: str, limit: int = 50) -> List[Dict[str, Any]]:
        """è·å–è¡¨æƒ…å†å²"""
        if session_id in self.emotion_history:
            history = self.emotion_history[session_id]
            return history[-limit:] if len(history) > limit else history
        return []
    
    def get_emotion_statistics(self, session_id: str) -> Dict[str, Any]:
        """è·å–è¡¨æƒ…ç»Ÿè®¡"""
        if session_id not in self.emotion_history:
            return {'error': 'æœªæ‰¾åˆ°å†å²æ•°æ®'}
        
        history = self.emotion_history[session_id]
        if not history:
            return {'error': 'å†å²æ•°æ®ä¸ºç©º'}
        
        try:
            # ç»Ÿè®¡è¡¨æƒ…åˆ†å¸ƒ
            emotion_counts = {}
            total_engagement = 0
            attention_levels = {'high': 0, 'medium': 0, 'low': 0}
            
            for record in history:
                summary = record.get('summary', {})
                
                emotion = summary.get('dominant_emotion', 'neutral')
                emotion_counts[emotion] = emotion_counts.get(emotion, 0) + 1
                
                total_engagement += summary.get('engagement_score', 0)
                
                attention = summary.get('attention_level', 'medium')
                attention_levels[attention] = attention_levels.get(attention, 0) + 1
            
            # è®¡ç®—ç»Ÿè®¡å€¼
            avg_engagement = total_engagement / len(history)
            most_common_emotion = max(emotion_counts, key=emotion_counts.get)
            
            return {
                'total_samples': len(history),
                'emotion_distribution': emotion_counts,
                'most_common_emotion': most_common_emotion,
                'average_engagement': round(avg_engagement, 2),
                'attention_distribution': attention_levels
            }
            
        except Exception as e:
            logger.error(f"è®¡ç®—è¡¨æƒ…ç»Ÿè®¡å¤±è´¥: {e}")
            return {'error': str(e)}
    
    def clear_session_data(self, session_id: str):
        """æ¸…ç†ä¼šè¯æ•°æ®"""
        if session_id in self.active_sessions:
            del self.active_sessions[session_id]
        
        if session_id in self.emotion_history:
            del self.emotion_history[session_id]
        
        logger.info(f"ä¼šè¯æ•°æ®å·²æ¸…ç†: {session_id}")

    def capture_screenshot(self) -> Optional[bytes]:
        """
        æˆªå–å±å¹•æˆªå›¾

        Returns:
            å›¾ç‰‡æ•°æ®ï¼ˆbytesæ ¼å¼ï¼‰
        """
        try:
            if SCREENSHOT_AVAILABLE:
                # æˆªå–å±å¹•
                screenshot = pyautogui.screenshot()

                # è½¬æ¢ä¸ºbytes
                img_buffer = io.BytesIO()
                screenshot.save(img_buffer, format='JPEG', quality=85)
                img_data = img_buffer.getvalue()

                logger.info(f"æˆªå›¾æˆåŠŸï¼Œå¤§å°: {len(img_data)} bytes")
                return img_data
            else:
                logger.warning("æˆªå›¾æ¨¡å—ä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæˆªå›¾æ•°æ®")
                return self._create_mock_image()

        except Exception as e:
            logger.error(f"æˆªå›¾å¤±è´¥: {e}")
            return self._create_mock_image()

    def _create_mock_image(self) -> bytes:
        """åˆ›å»ºæ¨¡æ‹Ÿå›¾ç‰‡æ•°æ®"""
        if SCREENSHOT_AVAILABLE:
            try:
                # åˆ›å»ºä¸€ä¸ªç®€å•çš„æ¨¡æ‹Ÿå›¾ç‰‡
                img = Image.new('RGB', (640, 480), color='lightblue')
                img_buffer = io.BytesIO()
                img.save(img_buffer, format='JPEG')
                return img_buffer.getvalue()
            except Exception as e:
                logger.error(f"åˆ›å»ºæ¨¡æ‹Ÿå›¾ç‰‡å¤±è´¥: {e}")

        # è¿”å›ä¸€ä¸ªæœ€å°çš„JPEGå¤´
        return b'\xff\xd8\xff\xe0\x00\x10JFIF\x00\x01\x01\x01\x00H\x00H\x00\x00\xff\xdb\x00C\x00\x08\x06\x06\x07\x06\x05\x08\x07\x07\x07\t\t\x08\n\x0c\x14\r\x0c\x0b\x0b\x0c\x19\x12\x13\x0f\x14\x1d\x1a\x1f\x1e\x1d\x1a\x1c\x1c $.\' ",#\x1c\x1c(7),01444\x1f\'9=82<.342\xff\xc0\x00\x11\x08\x01\xe0\x02\x80\x01\x01\x11\x00\x02\x11\x01\x03\x11\x01\xff\xc4\x00\x14\x00\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x08\xff\xc4\x00\x14\x10\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\xff\xda\x00\x0c\x03\x01\x00\x02\x11\x03\x11\x00\x3f\x00\xaa\xff\xd9'


# ä¸ºVisionServiceæ·»åŠ æ–°æ–¹æ³•
async def analyze_image_method(self, image_data: str):
    """åˆ†æå›¾åƒæ•°æ®ï¼ˆè¡¨æƒ…ã€å§¿æ€ã€çœ¼ç¥ç­‰ï¼‰- ä½¿ç”¨çœŸå®API"""
    try:
        # è§£ç base64å›¾ç‰‡æ•°æ®
        import base64
        if ',' in image_data:
            image_bytes = base64.b64decode(image_data.split(',')[1])
        else:
            image_bytes = base64.b64decode(image_data)

        # ä½¿ç”¨è®¯é£äººè„¸æ£€æµ‹API
        face_result = vision_service.detect_face_xunfei(image_bytes)
        if not face_result or not face_result.get('success'):
            logger.warning("äººè„¸æ£€æµ‹å¤±è´¥")
            return self._get_default_analysis_result()

        # ä½¿ç”¨è®¯é£è¡¨æƒ…åˆ†æAPI
        emotion_result = vision_service.analyze_expression_xunfei(image_bytes)

        # ç»¼åˆåˆ†æç»“æœ
        analysis_result = vision_service.comprehensive_analysis(image_bytes)

        # åœ¨ç»ˆç«¯æ˜¾ç¤ºåˆ†æç»“æœ
        if analysis_result.get('success'):
            summary = analysis_result.get('summary', 'åˆ†æå®Œæˆ')
            print(f"\nğŸ‘ï¸ [è§†è§‰åˆ†æ] {summary}")
            logger.info(f"è§†è§‰åˆ†æç»“æœ: {summary}")

        return analysis_result

    except Exception as e:
        logger.error(f"è§†è§‰åˆ†æå¤±è´¥: {e}")
        return {
            'success': False,
            'error': str(e),
            'summary': 'è§†è§‰åˆ†æå¤±è´¥'
        }

def _get_default_analysis_result() -> Dict[str, Any]:
    """è·å–é»˜è®¤åˆ†æç»“æœ"""
    return {
        'success': True,
        'face_detected': False,
        'emotion': 'neutral',
        'eye_contact': 0.5,
        'posture_score': 0.5,
        'facial_expression': 'neutral',
        'head_pose': {
            'pitch': 0,
            'yaw': 0,
            'roll': 0
        },
        'confidence': 0.5,
        'summary': 'æ— æ³•æ£€æµ‹åˆ°äººè„¸ï¼Œå»ºè®®è°ƒæ•´æ‘„åƒå¤´è§’åº¦'
    }

# åŠ¨æ€æ·»åŠ æ–¹æ³•åˆ°VisionServiceç±»
VisionService.analyze_image = analyze_image_method

# å…¨å±€æœåŠ¡å®ä¾‹
vision_service = VisionService()